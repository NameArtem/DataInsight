{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym OpenAI: Car Pole problem\n",
    "\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.\n",
    "\n",
    "CartPole gives a reward of 1.0 for each action taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "observation = env.reset()\n",
    "\n",
    "\n",
    "for episode in range(200):\n",
    "    for timestep in range(100):\n",
    "        env.render()\n",
    "    \n",
    "        print(observation)\n",
    "    \n",
    "        # Here we’ve chosen to “sample” the action space to get a random action, of which,\n",
    "        # there are only two: move left or move right.\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)  # take a random action\n",
    "\n",
    "        #if env_opt:\n",
    "        #    env.reset()\n",
    "        if done:\n",
    "            print(\"Completed after {} timesteps.\".format(timestep + 1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close environment\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do is train an agent to find a policy. we want to train our agent to find a good policy for the CartPole problem. Specifically, we want our agent to learn an ideally optimal policy that takes the four observation values and then make a decision as to what action to take (i.e. move right or move left) given the values the agent is observing at any given time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading material:\n",
    "    - http://testerstories.com/2017/12/the-tester-role-in-machine-learning-part-1/\n",
    "    - http://testerstories.com/2017/12/the-tester-role-in-machine-learning-part-2/\n",
    "    - http://testerstories.com/2017/12/the-tester-role-in-machine-learning-part-3/\n",
    "    - http://testerstories.com/2017/12/the-tester-role-in-machine-learning-part-4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
