{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Outlier_Detection_with_Isolation_Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHTXA6umka8D",
        "colab_type": "text"
      },
      "source": [
        "## Outlier Detection with Isolation Forest\n",
        "\n",
        "Isolation Forest, like any tree ensemble method, is built on the basis of decision trees. In these trees, partitions are created by first randomly selecting a feature and then selecting a random split value between the minimum and maximum value of the selected feature.\n",
        "\n",
        "In principle, outliers are less frequent than regular observations and are different from them in terms of values (they lie further away from the regular observations in the feature space). That is why by using such random partitioning they should be identified closer to the root of the tree (shorter average path length, i.e., the number of edges an observation must pass in the tree going from the root to the terminal node), with fewer splits necessary.\n",
        "\n",
        "A normal point requires more partitions to be identified than an abnormal point.\n",
        " \n",
        "As with other outlier detection methods, an anomaly score is required for decision making. In case of Isolation Forest it is defined as:\n",
        "\n",
        "\n",
        "> $s(x, n) = 2^-(\\frac{E(h(x))}{c(n)})$\n",
        "\n",
        "\n",
        "\n",
        "where h(x) is the path length of observation x, c(n) is the average path length of unsuccessful search in a Binary Search Tree and n is the number of external nodes. \n",
        "\n",
        "Each observation is given an anomaly score and the following decision can be made on its basis:\n",
        "\n",
        "- Score close to 1 indicates anomalies\n",
        "- Score much smaller than 0.5 indicates normal observations\n",
        "- If all scores are close to 0.5 than the entire sample does not seem to have clearly distinct anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwmQbn_nkOVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing libaries ----\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import savefig\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn import metrics\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkz3Yv9JlYki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating data ----\n",
        "rng = np.random.RandomState(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyqegRJlaID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating training data ----\n",
        "X_train = 0.2 * rng.randn(1000, 2)\n",
        "X_train = np.r_[X_train + 3, X_train]\n",
        "X_train = pd.DataFrame(X_train, columns = ['x1', 'x2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJF5ncPzlbkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating new, 'normal' observation ----\n",
        "X_test = 0.2 * rng.randn(200, 2)\n",
        "X_test = np.r_[X_test + 3, X_test]\n",
        "X_test = pd.DataFrame(X_test, columns = ['x1', 'x2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O90haprFldoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating outliers ----\n",
        "X_outliers = rng.uniform(low=-1, high=5, size=(50, 2))\n",
        "X_outliers = pd.DataFrame(X_outliers, columns = ['x1', 'x2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSFZf5o6lkc8",
        "colab_type": "text"
      },
      "source": [
        "## Isolation Forest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K2kmQlAleyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model ----\n",
        "clf = IsolationForest(max_samples=100, \n",
        "                      random_state=rng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB0h0YfxltZj",
        "colab_type": "code",
        "outputId": "9f16233d-cf5d-4e4f-d4d7-1580325a0bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Training the model ----\n",
        "clf.fit(X_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(behaviour='deprecated', bootstrap=False, contamination='auto',\n",
              "                max_features=1.0, max_samples=100, n_estimators=100,\n",
              "                n_jobs=None,\n",
              "                random_state=RandomState(MT19937) at 0x7F8A20CCAA98, verbose=0,\n",
              "                warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwBR9-DvlrxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions ----\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "y_pred_outliers = clf.predict(X_outliers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OKO-87fl1kI",
        "colab_type": "code",
        "outputId": "ba6e2e05-1522-42e2-b9f0-d771f794dbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# New, 'normal' observations ----\n",
        "print(\"Accuracy:\", list(y_pred_test).count(1)/y_pred_test.shape[0])\n",
        "# Accuracy: 0.93"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEq4JUbbl4dR",
        "colab_type": "code",
        "outputId": "741c5b22-f367-48c0-9ebd-48e745ffff55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Outliers ----\n",
        "print(\"Accuracy:\", list(y_pred_outliers).count(-1)/y_pred_outliers.shape[0])\n",
        "# Accuracy: 0.96"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7hxQ8qnreD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot CM ----\n",
        "def pretty_cm(y_pred, y_truth, labels):\n",
        "    '''\n",
        "    'Pretty' implementation of a confusion matrix with some evaluation statistics.\n",
        "    \n",
        "    Input:\n",
        "    y_pred - object with class predictions from the model\n",
        "    y_truth - object with actual classes\n",
        "    labels - list containing label names\n",
        "    '''\n",
        "\n",
        "    cm = metrics.confusion_matrix(y_truth, y_pred)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'BuGn_r')\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    ax.set_ylabel('Actual label')\n",
        "    ax.set_title('Confusion Matrix', size = 15) \n",
        "    ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels(labels)\n",
        "    \n",
        "    print('#######################')\n",
        "    print('Evaluation metrics ####')\n",
        "    print('#######################')\n",
        "    print('Accuracy: {:.4f}'.format(metrics.accuracy_score(y_truth, y_pred)))\n",
        "    print('Precision: {:.4f}'.format(metrics.precision_score(y_truth, y_pred)))\n",
        "    print('Recall: {:.4f}'.format(metrics.recall_score(y_truth, y_pred)))\n",
        "    print('F1: {:.4f}'.format(metrics.f1_score(y_truth, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULXHyANXnjk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretty_cm(y_pred_test, y_pred_test, [0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbI0yG4_nX1Z",
        "colab_type": "code",
        "outputId": "73ccc1dc-7bca-4ad2-a245-c31fbc16bd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install eif"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eif in /usr/local/lib/python3.6/dist-packages (2.0.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from eif) (0.29.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from eif) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jOGXLDpoEmE",
        "colab_type": "text"
      },
      "source": [
        "## Extended Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ne12FjnWN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import eif as iso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTHM71TOl49n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting ExtensionLevel to 0 ----\n",
        "if_eif = iso.iForest(X_train.values, \n",
        "                     ntrees = 100, \n",
        "                     sample_size = 256, \n",
        "                     ExtensionLevel = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJmHXBhvoM_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate anomaly scores ----\n",
        "anomaly_scores = if_eif.compute_paths(X_in = X_train.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qhNMih5oYXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort the scores ----\n",
        "anomaly_scores_sorted = np.argsort(anomaly_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMb4YKQMoZ_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define % of anomalies ----\n",
        "anomalies_ratio = 0.009\n",
        "\n",
        "#retrieve indices of anomalous observations\n",
        "indices_with_preds = anomaly_scores_sorted[-int(np.ceil(anomalies_ratio * X_train.shape[0])):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXocJK2ox-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the level to 9 (number of dimensions - 1)\n",
        "eif = iso.iForest(X_train.values, \n",
        "                  ntrees = 100, \n",
        "                  sample_size = 256, \n",
        "                  ExtensionLevel = X_train.shape[1] - 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASiSKxlKoyGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anomaly_scores = eif.compute_paths(X_in = X_train.values)\n",
        "anomaly_scores_sorted = np.argsort(anomaly_scores)\n",
        "indices_with_preds = anomaly_scores_sorted[-int(np.ceil(anomalies_ratio * X_train.shape[0])):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leZadzhAqNw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}