{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-3XeFC4hxUF",
        "colab_type": "text"
      },
      "source": [
        "## A Custom Estimator for a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k3tr9NKhvPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwGIM6GBimdF",
        "colab_type": "text"
      },
      "source": [
        "Import the dataset. Here, we'll need to convert the labels to a one-hot encoding, and we'll reshape the MNIST images to (784,)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioMoNAVAh2-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a7985c3c-5244-44a5-af42-0813e46a1f64"
      },
      "source": [
        "# Set dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.contrib.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "\n",
        "y_train = y_train.astype('int32')\n",
        "y_test  = y_test.astype('int32')\n",
        "\n",
        "# Normalize the color values to 0-1\n",
        "# (as imported, they're 0-255)\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# The CNN we'll use later expects a color channel dimension\n",
        "# Let's add this here\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test  = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Convert to one-hot encoded.\n",
        "y_train = tf.contrib.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test  = tf.contrib.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ4u54tziqkC",
        "colab_type": "text"
      },
      "source": [
        "### Defines Convolutional Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEYOup7uiLry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn(features, mode):\n",
        "    \n",
        "    image_batch = features['x']\n",
        "    \n",
        "    with tf.name_scope(\"conv1\"):  \n",
        "        conv1 = tf.layers.conv2d(inputs=image_batch, filters=32, kernel_size=[3, 3],\n",
        "                                 padding='same', activation=tf.nn.relu)\n",
        "\n",
        "    with tf.name_scope(\"pool1\"):  \n",
        "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    with tf.name_scope(\"conv2\"):  \n",
        "        conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3, 3],\n",
        "                                 padding='same', activation=tf.nn.relu)\n",
        "\n",
        "    with tf.name_scope(\"pool2\"):  \n",
        "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    with tf.name_scope(\"dense\"):  \n",
        "        # The 'images' are now 7x7 (28 / 2 / 2), and we have 64 channels per image\n",
        "        pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "        dense = tf.layers.dense(inputs=pool2_flat, units=128, activation=tf.nn.relu)\n",
        "\n",
        "    with tf.name_scope(\"dropout\"):  \n",
        "        # Add dropout operation; 0.8 probability that a neuron will be kept\n",
        "        dropout = tf.layers.dropout(\n",
        "            inputs=dense, rate=0.2, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1VnmZoGiRY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(features, labels, mode):\n",
        "    \n",
        "    logits = build_cnn(features, mode)\n",
        "    \n",
        "    # Generate Predictions\n",
        "    classes = tf.argmax(logits, axis=1)\n",
        "    predictions = {\n",
        "        'classes': classes,\n",
        "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
        "    }\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        # Return an EstimatorSpec for prediction\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "        \n",
        "    # Compute the loss, per usual.\n",
        "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, \n",
        "                                           logits=logits)\n",
        "        \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        \n",
        "        # Configure the Training Op\n",
        "        train_op = tf.contrib.layers.optimize_loss(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step(),\n",
        "            learning_rate=1e-3,\n",
        "            optimizer='Adam')\n",
        "\n",
        "        # Return an EstimatorSpec for training\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
        "                                      loss=loss, train_op=train_op)    \n",
        "\n",
        "    assert mode == tf.estimator.ModeKeys.EVAL\n",
        "    \n",
        "    # Configure the accuracy metric for evaluation\n",
        "    metrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, axis=1))}\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode=mode, \n",
        "                                      predictions=predictions, \n",
        "                                      loss=loss,\n",
        "                                      eval_metric_ops=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxanO_lIiTFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = tf.estimator.inputs.numpy_input_fn(\n",
        "    {'x': x_train},\n",
        "    y_train, \n",
        "    num_epochs=None, # repeat forever\n",
        "    shuffle=True # shuffle the training data\n",
        ")\n",
        "\n",
        "test_input = tf.estimator.inputs.numpy_input_fn(\n",
        "    {'x': x_test},\n",
        "    y_test,\n",
        "    num_epochs=1, # loop through the dataset once\n",
        "    shuffle=False # don't shuffle the test data\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C-B6XdUiTHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "2fbe94d3-c576-482c-8f38-6e63a16ad369"
      },
      "source": [
        "# Set classification estimator\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8fxpwy98\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8fxpwy98', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f621d8407f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioVZljOUiTLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1380
        },
        "outputId": "d25dd08e-ec62-486f-ae07-08b21ebc1d2b"
      },
      "source": [
        "# If you are running on a machine without a GPU, this can take some time to train.\n",
        "estimator.train(input_fn=train_input, steps=2000)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-3-6b161f6842ba>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-6b161f6842ba>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-6b161f6842ba>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-3-6b161f6842ba>:27: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8fxpwy98/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.2878103, step = 1\n",
            "INFO:tensorflow:global_step/sec: 6.12769\n",
            "INFO:tensorflow:loss = 0.14022605, step = 101 (16.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.00585\n",
            "INFO:tensorflow:loss = 0.1564011, step = 201 (16.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.00532\n",
            "INFO:tensorflow:loss = 0.06864096, step = 301 (16.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.03573\n",
            "INFO:tensorflow:loss = 0.06003457, step = 401 (16.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.99645\n",
            "INFO:tensorflow:loss = 0.05992481, step = 501 (16.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.99193\n",
            "INFO:tensorflow:loss = 0.13698, step = 601 (16.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.85628\n",
            "INFO:tensorflow:loss = 0.019767612, step = 701 (17.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.01299\n",
            "INFO:tensorflow:loss = 0.07084819, step = 801 (16.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.98408\n",
            "INFO:tensorflow:loss = 0.044335384, step = 901 (16.711 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.01462\n",
            "INFO:tensorflow:loss = 0.048819978, step = 1001 (16.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.08585\n",
            "INFO:tensorflow:loss = 0.03031628, step = 1101 (16.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.99779\n",
            "INFO:tensorflow:loss = 0.067993745, step = 1201 (16.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.06583\n",
            "INFO:tensorflow:loss = 0.044495296, step = 1301 (16.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.08392\n",
            "INFO:tensorflow:loss = 0.00850089, step = 1401 (16.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.13084\n",
            "INFO:tensorflow:loss = 0.020303223, step = 1501 (16.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.05451\n",
            "INFO:tensorflow:loss = 0.010185983, step = 1601 (16.514 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.1252\n",
            "INFO:tensorflow:loss = 0.030180823, step = 1701 (16.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.10439\n",
            "INFO:tensorflow:loss = 0.03374592, step = 1801 (16.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.08247\n",
            "INFO:tensorflow:loss = 0.02947379, step = 1901 (16.439 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp8fxpwy98/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0040472886.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f621d840550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IzF6hDpiZwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "722be5c1-3541-4c4f-b02b-af38d9abd65d"
      },
      "source": [
        "# Evaluate the estimator using our input function.\n",
        "# We should see our accuracy metric below\n",
        "# Tweaking with the params of the model, you can get >99% accuracy\n",
        "evaluation = estimator.evaluate(input_fn=test_input)\n",
        "print(evaluation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-06-02T14:22:20Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8fxpwy98/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-06-02-14:22:24\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9909, global_step = 2000, loss = 0.025070133\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmp8fxpwy98/model.ckpt-2000\n",
            "{'accuracy': 0.9909, 'loss': 0.025070133, 'global_step': 2000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q4wIrQbibfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d30244ff-1a9b-4b50-b0a5-9a8438002305"
      },
      "source": [
        "# Here's how to print predictions on a few examples\n",
        "MAX_TO_PRINT = 5\n",
        "\n",
        "# This returns a generator object\n",
        "predictions = estimator.predict(input_fn=test_input)\n",
        "\n",
        "i = 0\n",
        "for p in predictions:\n",
        "    true_label = np.argmax(y_test[i])\n",
        "    predicted_label = p['classes']\n",
        "    print(\"Example %d. True: %d, Predicted: %s\" % (i, true_label, predicted_label))\n",
        "    i += 1\n",
        "    if i == MAX_TO_PRINT: break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8fxpwy98/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Example 0. True: 7, Predicted: 7\n",
            "Example 1. True: 2, Predicted: 2\n",
            "Example 2. True: 1, Predicted: 1\n",
            "Example 3. True: 0, Predicted: 0\n",
            "Example 4. True: 4, Predicted: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdzVyn_Xs-Az",
        "colab_type": "text"
      },
      "source": [
        "With CNN we achieve around 99% accuracy on MNIST, but there is still plenty of room to improve, we could try using cutting-edge CNN architectures such as ResNet, Inception, and VGG and do a comparison study."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfGFfTvFjM8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}