{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bike Sharing Problem - Model building and inference\n",
    "\n",
    "This notebook documents the analysis and model development for the Bike Sharing Dataset.\n",
    "\n",
    "$\\bf{Goal}$: To goal is to build a predictive model for the number of bike rides an hour based on time of year and weather. In particular we are interested in predicting the number of rides, cnt.\n",
    "\n",
    "The characteristics of the given problem are\n",
    "\n",
    "- Regression: The target variable is a quantity.\n",
    "- Small dataset: Less than 20K samples.\n",
    "- Few features should be important.\n",
    "    * The correlation matrix indicates that a few features contain the information to predict the target variable.\n",
    "\n",
    "It contains the following steps:\n",
    "- Overview metrics\n",
    "- Model building\n",
    "- Model Selection\n",
    "  * Linear Regession\n",
    "  * Tree-based Ensemble Regression\n",
    "  * Feature importance\n",
    "- Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading required package\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sklearn metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import Lasso, ElasticNet, Ridge, SGDRegressor, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Sklearn untility functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# XGBoost, Catboost, and LightGBM models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgbm\n",
    "\n",
    "# Beautify evaluation tables\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path \n",
    "base_dir = '/Users/chrisjcc/Downloads/'\n",
    "\n",
    "data_path = base_dir + 'hour.csv'\n",
    "# Load data\n",
    "data = pd.read_csv(data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check of proper loading of dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "This step involves cleaning the data, dropping unwanted columns, converting the categorical variables to numeric, and finally splitting of training data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Renaming columns names to more readable names\n",
    "data.rename(columns={'instant':'rec_id',\n",
    "                     'dteday':'datetime',\n",
    "                     'holiday':'is_holiday',\n",
    "                     'workingday':'is_workingday',\n",
    "                     'weathersit':'weather_condition',\n",
    "                     'hum':'humidity',\n",
    "                     'mnth':'month',\n",
    "                     'cnt':'total_count',\n",
    "                     'hr':'hour',\n",
    "                     'yr':'year',\n",
    "                    },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting proper data types\n",
    "\n",
    "# date time conversion\n",
    "data['datetime'] = pd.to_datetime(data.datetime)\n",
    "\n",
    "# categorical fetures\n",
    "data['season']     = data.season.astype('category')\n",
    "data['is_holiday'] = data.is_holiday.astype('category')\n",
    "data['weekday']    = data.weekday.astype('category')\n",
    "data['weather_condition'] = data.weather_condition.astype('category')\n",
    "data['is_workingday']     = data.is_workingday.astype('category')\n",
    "data['month'] = data.month.astype('category')\n",
    "data['hour']  = data.hour.astype('category')\n",
    "data['year']  = data.year.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "Each observation can either be used for building a model or evaluating a model, not both. For this reason we must perform a train/test partition of the main dataset be used for model training and evaluation, respectively. We'll use this set to make predictions and compare them with the actual number of bike riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing sets (randomly and stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:-3],\n",
    "                                                    data.iloc[:,-1],\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=None,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11643 training samples and 5736 test samples.\n"
     ]
    }
   ],
   "source": [
    "# Training data used for model developement\n",
    "X_train.reset_index(inplace=True)\n",
    "y_train = y_train.reset_index()\n",
    "\n",
    "# Set aside a hold-out test data used for final model performance\n",
    "X_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()\n",
    "print(\"We have %d training samples and %d test samples.\" % (y_train['total_count'].count(), \n",
    "                                                            y_test['total_count'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "We take as a baseline model a model that does not depend applying any machine learning techniques. We will use Mean Absoluate Deivation (MAD) as the evaluation metric for model performance.\n",
    "\n",
    "\n",
    "#### Evaluation metric\n",
    "\n",
    "The Mean Absolute Deviation (MAD) helps determine whether the set's mean is a useful indicator of the values within the set. The larger the MAD, the less relevant is the mean as an indicator of the values within the set. (MAD), the greater variability there is in the data (the data is more spread out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basline Mean Absolute Deviation of Validation data: 141.78\n"
     ]
    }
   ],
   "source": [
    "# Average bike usage from training data\n",
    "avg_bike_usuage = round(np.mean(y_train['total_count']), 2)\n",
    "baseline_pred   = np.repeat(avg_bike_usuage, y_test.shape[0])\n",
    "\n",
    "# Evaluate baseline model\n",
    "baseline_mae = mean_absolute_error(baseline_pred, y_test['total_count'])\n",
    "\n",
    "print(\"Basline Mean Absolute Deviation of Validation data: %.2f\" % baseline_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict the average bike usage. This resulted in an MAD of 141.78. So any model we build should have an MAD lower than 141.78."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Feature Engineering\n",
    "\n",
    "In the following section we will compare linear regresssion/SGD based algorithms against tree-ensemble based methods to see which group performs best out of the box using mean absolute devaition metric evaluation. For linear ression modeling requires converting the cateogrical features into numeric featuers, while tree-based models do not need to transform them or can handle that step internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defiting One-hot-encoding and Label-encoding transformation function\n",
    "def fit_transform_ohe(df,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "column.\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        col_name: the column to be one hot encoded\n",
    "    Returns:\n",
    "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n",
    "    \"\"\"\n",
    "    # label encode the column\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name+'_label'] = le_labels\n",
    "    # one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    return le,ohe,features_df\n",
    "\n",
    "# given label encoder and one hot encoder objects, \n",
    "# encode attribute to ohe\n",
    "def transform_ohe(df,le,ohe,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "        column using the specified encoder objects.\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        le(Label Encoder): the label encoder object used to fit label encoding\n",
    "        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n",
    "        col_name: the column to be one hot encoded\n",
    "\n",
    "    Returns:\n",
    "        tuple: transformed column as pandas Series\n",
    "\n",
    "    \"\"\"\n",
    "    # label encode\n",
    "    col_labels = le.transform(df[col_name])\n",
    "    df[col_name+'_label'] = col_labels\n",
    "    \n",
    "    # ohe \n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding all the categorical features\n",
    "cat_attr_list = ['season','is_holiday',\n",
    "                 'weather_condition','is_workingday',\n",
    "                 'hour','weekday','month',#'year'\n",
    "                ]\n",
    "\n",
    "# though we have transformed all categoricals into their one-hot encodings, note that ordinal\n",
    "# attributes such as hour, weekday, and so on do not require such encoding.\n",
    "numeric_feature_cols = ['temp','humidity','windspeed', 'atemp',\n",
    "                        'hour','weekday','month',#'year'\n",
    "                       ]\n",
    "subset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape::(11643, 19)\n",
      "   temp  humidity  windspeed   atemp hour weekday month  season_1  season_2  \\\n",
      "0  0.64      0.65     0.1940  0.6061    0       5     9       0.0       0.0   \n",
      "1  0.50      0.45     0.2239  0.4848   13       2     3       0.0       1.0   \n",
      "2  0.86      0.47     0.5224  0.8030   12       0     8       0.0       0.0   \n",
      "3  0.30      0.61     0.0000  0.3333    2       3     2       1.0       0.0   \n",
      "4  0.54      0.19     0.4179  0.5152   17       6     4       0.0       1.0   \n",
      "\n",
      "   season_3  season_4  is_holiday_0  is_holiday_1  weather_condition_1  \\\n",
      "0       1.0       0.0           1.0           0.0                  1.0   \n",
      "1       0.0       0.0           1.0           0.0                  1.0   \n",
      "2       1.0       0.0           1.0           0.0                  1.0   \n",
      "3       0.0       0.0           1.0           0.0                  1.0   \n",
      "4       0.0       0.0           1.0           0.0                  1.0   \n",
      "\n",
      "   weather_condition_2  weather_condition_3  weather_condition_4  \\\n",
      "0                  0.0                  0.0                  0.0   \n",
      "1                  0.0                  0.0                  0.0   \n",
      "2                  0.0                  0.0                  0.0   \n",
      "3                  0.0                  0.0                  0.0   \n",
      "4                  0.0                  0.0                  0.0   \n",
      "\n",
      "   is_workingday_0  is_workingday_1  \n",
      "0              0.0              1.0  \n",
      "1              0.0              1.0  \n",
      "2              1.0              0.0  \n",
      "3              0.0              1.0  \n",
      "4              1.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Train dataset\n",
    "encoded_attr_list = []\n",
    "for col in cat_attr_list:\n",
    "    return_obj = fit_transform_ohe(X_train,col)\n",
    "    encoded_attr_list.append({'label_enc':return_obj[0],\n",
    "                              'ohe_enc':return_obj[1],\n",
    "                              'feature_df':return_obj[2],\n",
    "                              'col_name':col})\n",
    "\n",
    "\n",
    "feature_df_list  = [X_train[numeric_feature_cols]]\n",
    "feature_df_list.extend([enc['feature_df'] \\\n",
    "                        for enc in encoded_attr_list \\\n",
    "                        if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "train_df_new = pd.concat(feature_df_list, axis=1)\n",
    "print(\"Train dataset shape::{}\".format(train_df_new.shape))\n",
    "print(train_df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape::(5736, 19)\n",
      "   temp  humidity  windspeed   atemp hour weekday month  season_1  season_2  \\\n",
      "0  0.80      0.27     0.1940  0.6970   19       6     6       0.0       0.0   \n",
      "1  0.24      0.41     0.2239  0.2273   20       1     1       1.0       0.0   \n",
      "2  0.32      0.66     0.2836  0.3030    2       5    10       0.0       0.0   \n",
      "3  0.78      0.52     0.3582  0.7121   19       2     5       0.0       1.0   \n",
      "4  0.26      0.56     0.3881  0.2273    0       4     1       1.0       0.0   \n",
      "\n",
      "   season_3  season_4  is_holiday_0  is_holiday_1  weather_condition_1  \\\n",
      "0       1.0       0.0           1.0           0.0                  1.0   \n",
      "1       0.0       0.0           0.0           1.0                  1.0   \n",
      "2       0.0       1.0           1.0           0.0                  1.0   \n",
      "3       0.0       0.0           1.0           0.0                  1.0   \n",
      "4       0.0       0.0           1.0           0.0                  1.0   \n",
      "\n",
      "   weather_condition_2  weather_condition_3  weather_condition_4  \\\n",
      "0                  0.0                  0.0                  0.0   \n",
      "1                  0.0                  0.0                  0.0   \n",
      "2                  0.0                  0.0                  0.0   \n",
      "3                  0.0                  0.0                  0.0   \n",
      "4                  0.0                  0.0                  0.0   \n",
      "\n",
      "   is_workingday_0  is_workingday_1  \n",
      "0              1.0              0.0  \n",
      "1              1.0              0.0  \n",
      "2              0.0              1.0  \n",
      "3              0.0              1.0  \n",
      "4              0.0              1.0  \n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "test_encoded_attr_list = []\n",
    "for enc in encoded_attr_list:\n",
    "    col_name = enc['col_name']\n",
    "    le = enc['label_enc']\n",
    "    ohe = enc['ohe_enc']\n",
    "    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,le,ohe,col_name),'col_name':col_name})\n",
    "    \n",
    "    \n",
    "test_feature_df_list = [X_test[numeric_feature_cols]]\n",
    "test_feature_df_list.extend([enc['feature_df'] \\\n",
    "                             for enc in test_encoded_attr_list \\\n",
    "                             if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "test_df_new = pd.concat(test_feature_df_list, axis=1) \n",
    "print(\"Test dataset shape::{}\".format(test_df_new.shape))\n",
    "print(test_df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train dataset\n",
    "X_train = train_df_new\n",
    "y_train = y_train.total_count.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test dataset\n",
    "X_test = test_df_new\n",
    "y_test = y_test.total_count.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"Dataset\", \"MAE\", \"MSE\", \"R² score\", \"Variance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "models = [\n",
    "    # specify the hyper-parameters \n",
    "    LinearRegression(),\n",
    "    Lasso(alpha=0.1),\n",
    "    ElasticNet(random_state=0),\n",
    "    Ridge(alpha=.5),\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.49\n",
      "108.47\n",
      "119.80\n",
      "108.49\n",
      "107.75\n",
      "+------------------+----------+--------+----------+----------+----------+\n",
      "|      Model       | Dataset  |  MAE   |   MSE    | R² score | Variance |\n",
      "+------------------+----------+--------+----------+----------+----------+\n",
      "| LinearRegression | training | 108.73 | 20413.31 |   0.36   |   0.24   |\n",
      "|      Lasso       | training | 108.70 | 20420.14 |   0.36   |   0.23   |\n",
      "|    ElasticNet    | training | 119.86 | 24493.28 |   0.23   |   0.06   |\n",
      "|      Ridge       | training | 108.73 | 20413.26 |   0.36   |   0.23   |\n",
      "|   SGDRegressor   | training | 106.68 | 20657.63 |   0.35   |   1.07   |\n",
      "+------------------+----------+--------+----------+----------+----------+\n",
      "CPU times: user 1.11 s, sys: 969 ms, total: 2.08 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model in models:\n",
    "    dataset = 'training'\n",
    "    \n",
    "    # Model training\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make prediction on test and training data set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_res  = model.predict(X_train)\n",
    "\n",
    "    # Evaluate model performance (for shortness of time will only CV MAE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # Cross-Validated Mean Absolute Deviation regression loss\n",
    "    mae = -np.mean(cross_val_score(model, X_train, y_train, cv=3, n_jobs=-1, scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "    \n",
    "    \n",
    "    variance  = abs(mean_absolute_error(y_train, y_res) - mae)\n",
    "    \n",
    "    print(\"%.2f\" % mean_absolute_error(y_train, y_res))\n",
    "\n",
    "    \n",
    "    table.add_row([type(model).__name__, \n",
    "                   dataset,\n",
    "                   format(mae, '.2f'),\n",
    "                   format(mse, '.2f'),   \n",
    "                   format(score, '.2f'),\n",
    "                   format(variance, '.2f')\n",
    "                  ],\n",
    "                 )\n",
    "    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table summary of model's performance across various evaluation metrics typically used in regression problems. For our purposes the most import one being the Mean Absolute Deviation (MAE).\n",
    "\n",
    "```\n",
    "+------------------+----------+--------+----------+----------+----------+\n",
    "|      Model       | Dataset  |  MAE   |   MSE    | R² score | Variance |\n",
    "+------------------+----------+--------+----------+----------+----------+\n",
    "| LinearRegression | training | 108.73 | 20413.31 |   0.36   |   0.24   |\n",
    "|      Lasso       | training | 108.70 | 20420.14 |   0.36   |   0.23   |\n",
    "|    ElasticNet    | training | 119.86 | 24493.28 |   0.23   |   0.06   |\n",
    "|      Ridge       | training | 108.73 | 20413.26 |   0.36   |   0.23   |\n",
    "|   SGDRegressor   | training | 106.68 | 20657.63 |   0.35   |   1.07   |\n",
    "+------------------+----------+--------+----------+----------+----------+\n",
    "```\n",
    "\n",
    "The test MAD for Linear Regression-based/SGD model range between 108-119, and the training was 107-119, which provides confidence that's no problem of overfitting is there's not gap between training and test performance range for MAE. These models are an improvement on the baseline prediction which had mean asolute error of 141.78. Still, the error rate is very high in this linear regression models, though the variance is relatively low (0.23-16.86). As we also so in the other metrics they have quite high values an R² score closer to 1. is and indicator of better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate model's performance using validation dataset\n",
    "predicted = cross_val_predict(Lasso(alpha=0.1), \n",
    "                              X_train, y_train, \n",
    "                              cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12031fdd0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysing Residuals in model's predictinos\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(y_train, y_train-predicted.reshape(-1,1))\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This residual plots shows a linear trend across observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble tree-based algorithms\n",
    "\n",
    "As these tree-based methods have build in handling of categorical feature we will need to re-load data that are not one-hot-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11643 training samples and 5736 test samples.\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into training and testing sets (randomly and stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:-3],\n",
    "                                                    data.iloc[:,-1],\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=None,\n",
    "                                                    random_state=42)\n",
    "# Training data used for model developement\n",
    "X_train.reset_index(inplace=True)\n",
    "y_train = y_train.reset_index()\n",
    "\n",
    "# Set aside a hold-out test data used for final model performance\n",
    "X_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()\n",
    "print(\"We have %d training samples and %d test samples.\" % (y_train['total_count'].count(), \n",
    "                                                            y_test['total_count'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform train dataset\n",
    "y_train = y_train['total_count']\n",
    "\n",
    "X_train = X_train[['season', 'month','hour','is_holiday','weekday','is_workingday', #'year'\n",
    "                   'weather_condition','temp','atemp','humidity','windspeed']]\n",
    "\n",
    "# transform test dataset\n",
    "y_test = y_test['total_count']\n",
    "X_test = X_test[['season','month','hour','is_holiday','weekday','is_workingday', #'year'\n",
    "                 'weather_condition','temp','atemp','humidity','windspeed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building, selection, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "models = [\n",
    "    # specify the training parameters \n",
    "    CatBoostRegressor(loss_function='MAE', #'RMSE', \n",
    "                      max_depth=3, #None\n",
    "                      cat_features=cat_attr_list,\n",
    "                      random_state=42\n",
    "                     ),\n",
    "    lgbm.sklearn.LGBMRegressor(boosting_type='gbdt', \n",
    "                               objective='regression',\n",
    "                               min_child_samples=10,  \n",
    "                               max_depth=-1,\n",
    "                               categorical_feature=cat_attr_list,\n",
    "                               nthread=-1,\n",
    "                               random_state=42\n",
    "                              ),\n",
    "    GradientBoostingRegressor(max_depth=3, \n",
    "                              min_samples_leaf=10, \n",
    "                              random_state=42),\n",
    "    AdaBoostRegressor(DecisionTreeRegressor(max_depth=3, #None \n",
    "                                            min_samples_leaf=10,\n",
    "                                            criterion='mae',\n",
    "                                           ),\n",
    "                      random_state=42),\n",
    "    RandomForestRegressor(criterion='mae', \n",
    "                          min_samples_leaf=10,\n",
    "                          max_depth=None, # If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "                          random_state=42,\n",
    "                          n_jobs=-1,\n",
    "                         ),\n",
    "    \n",
    "    #XGBClassifier(max_depth=3, #None\n",
    "    #              objective='count:poisson', #'reg:linear', \n",
    "    #              min_samples_leaf=10,\n",
    "    #              random_state=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the the evaluation metrics of intereset (Mean Absolute Devation is prirmery)\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"Dataset\", \"MAE\", \"MSE\", \"R² score\", \"Variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 186.9027166\ttotal: 62.2ms\tremaining: 1m 2s\n",
      "1:\tlearn: 182.8514863\ttotal: 71ms\tremaining: 35.4s\n",
      "2:\tlearn: 179.1605979\ttotal: 76.2ms\tremaining: 25.3s\n",
      "3:\tlearn: 175.9949443\ttotal: 81.2ms\tremaining: 20.2s\n",
      "4:\tlearn: 172.8566851\ttotal: 86.3ms\tremaining: 17.2s\n",
      "5:\tlearn: 168.9716858\ttotal: 90.6ms\tremaining: 15s\n",
      "6:\tlearn: 165.2641333\ttotal: 94.4ms\tremaining: 13.4s\n",
      "7:\tlearn: 161.6188686\ttotal: 98.9ms\tremaining: 12.3s\n",
      "8:\tlearn: 158.1229357\ttotal: 102ms\tremaining: 11.3s\n",
      "9:\tlearn: 154.7225800\ttotal: 106ms\tremaining: 10.5s\n",
      "10:\tlearn: 151.4098894\ttotal: 109ms\tremaining: 9.79s\n",
      "11:\tlearn: 148.1761757\ttotal: 112ms\tremaining: 9.23s\n",
      "12:\tlearn: 145.0735339\ttotal: 115ms\tremaining: 8.76s\n",
      "13:\tlearn: 142.1768407\ttotal: 118ms\tremaining: 8.33s\n",
      "14:\tlearn: 139.7084826\ttotal: 122ms\tremaining: 7.98s\n",
      "15:\tlearn: 137.1237237\ttotal: 125ms\tremaining: 7.68s\n",
      "16:\tlearn: 134.3574697\ttotal: 128ms\tremaining: 7.42s\n",
      "17:\tlearn: 131.9162037\ttotal: 132ms\tremaining: 7.21s\n",
      "18:\tlearn: 129.4784811\ttotal: 136ms\tremaining: 7s\n",
      "19:\tlearn: 127.1350282\ttotal: 139ms\tremaining: 6.81s\n",
      "20:\tlearn: 124.8939909\ttotal: 142ms\tremaining: 6.64s\n",
      "21:\tlearn: 122.7108968\ttotal: 146ms\tremaining: 6.47s\n",
      "22:\tlearn: 120.6172051\ttotal: 149ms\tremaining: 6.32s\n",
      "23:\tlearn: 118.6857803\ttotal: 152ms\tremaining: 6.2s\n",
      "24:\tlearn: 116.7750703\ttotal: 156ms\tremaining: 6.08s\n",
      "25:\tlearn: 115.0859550\ttotal: 159ms\tremaining: 5.96s\n",
      "26:\tlearn: 113.2013002\ttotal: 163ms\tremaining: 5.86s\n",
      "27:\tlearn: 111.5915006\ttotal: 166ms\tremaining: 5.75s\n",
      "28:\tlearn: 110.0399069\ttotal: 169ms\tremaining: 5.65s\n",
      "29:\tlearn: 108.4877110\ttotal: 172ms\tremaining: 5.55s\n",
      "30:\tlearn: 107.0850039\ttotal: 175ms\tremaining: 5.47s\n",
      "31:\tlearn: 105.7335810\ttotal: 179ms\tremaining: 5.41s\n",
      "32:\tlearn: 104.4172462\ttotal: 182ms\tremaining: 5.34s\n",
      "33:\tlearn: 103.2125091\ttotal: 186ms\tremaining: 5.28s\n",
      "34:\tlearn: 102.0138098\ttotal: 189ms\tremaining: 5.2s\n",
      "35:\tlearn: 100.9163550\ttotal: 192ms\tremaining: 5.15s\n",
      "36:\tlearn: 99.8892768\ttotal: 196ms\tremaining: 5.1s\n",
      "37:\tlearn: 98.9036812\ttotal: 200ms\tremaining: 5.06s\n",
      "38:\tlearn: 97.7748261\ttotal: 203ms\tremaining: 5s\n",
      "39:\tlearn: 96.8205775\ttotal: 207ms\tremaining: 4.97s\n",
      "40:\tlearn: 95.9281416\ttotal: 210ms\tremaining: 4.91s\n",
      "41:\tlearn: 95.1390185\ttotal: 214ms\tremaining: 4.87s\n",
      "42:\tlearn: 94.3925353\ttotal: 220ms\tremaining: 4.89s\n",
      "43:\tlearn: 93.6490277\ttotal: 223ms\tremaining: 4.85s\n",
      "44:\tlearn: 92.9567065\ttotal: 228ms\tremaining: 4.83s\n",
      "45:\tlearn: 92.1989337\ttotal: 231ms\tremaining: 4.79s\n",
      "46:\tlearn: 91.4142040\ttotal: 234ms\tremaining: 4.75s\n",
      "47:\tlearn: 90.6343951\ttotal: 238ms\tremaining: 4.72s\n",
      "48:\tlearn: 89.9503722\ttotal: 241ms\tremaining: 4.68s\n",
      "49:\tlearn: 89.4169459\ttotal: 245ms\tremaining: 4.65s\n",
      "50:\tlearn: 88.8321711\ttotal: 248ms\tremaining: 4.62s\n",
      "51:\tlearn: 88.2904504\ttotal: 251ms\tremaining: 4.58s\n",
      "52:\tlearn: 87.6423730\ttotal: 256ms\tremaining: 4.57s\n",
      "53:\tlearn: 87.1104536\ttotal: 263ms\tremaining: 4.6s\n",
      "54:\tlearn: 86.6077686\ttotal: 269ms\tremaining: 4.62s\n",
      "55:\tlearn: 86.0991892\ttotal: 275ms\tremaining: 4.63s\n",
      "56:\tlearn: 85.6327327\ttotal: 279ms\tremaining: 4.62s\n",
      "57:\tlearn: 85.2281851\ttotal: 286ms\tremaining: 4.65s\n",
      "58:\tlearn: 84.5533754\ttotal: 292ms\tremaining: 4.66s\n",
      "59:\tlearn: 83.7744304\ttotal: 295ms\tremaining: 4.63s\n",
      "60:\tlearn: 83.0428477\ttotal: 299ms\tremaining: 4.61s\n",
      "61:\tlearn: 82.4372930\ttotal: 304ms\tremaining: 4.6s\n",
      "62:\tlearn: 81.8703488\ttotal: 308ms\tremaining: 4.58s\n",
      "63:\tlearn: 81.3112846\ttotal: 311ms\tremaining: 4.55s\n",
      "64:\tlearn: 80.6929371\ttotal: 315ms\tremaining: 4.53s\n",
      "65:\tlearn: 80.1460235\ttotal: 318ms\tremaining: 4.5s\n",
      "66:\tlearn: 79.8502930\ttotal: 321ms\tremaining: 4.47s\n",
      "67:\tlearn: 79.3187701\ttotal: 324ms\tremaining: 4.44s\n",
      "68:\tlearn: 78.8093635\ttotal: 327ms\tremaining: 4.42s\n",
      "69:\tlearn: 78.2887145\ttotal: 331ms\tremaining: 4.39s\n",
      "70:\tlearn: 77.8564318\ttotal: 334ms\tremaining: 4.37s\n",
      "71:\tlearn: 77.3583712\ttotal: 337ms\tremaining: 4.35s\n",
      "72:\tlearn: 76.9477641\ttotal: 341ms\tremaining: 4.32s\n",
      "73:\tlearn: 76.5022759\ttotal: 344ms\tremaining: 4.3s\n",
      "74:\tlearn: 76.0723518\ttotal: 347ms\tremaining: 4.28s\n",
      "75:\tlearn: 75.6651546\ttotal: 350ms\tremaining: 4.26s\n",
      "76:\tlearn: 75.2814641\ttotal: 354ms\tremaining: 4.24s\n",
      "77:\tlearn: 74.8990084\ttotal: 357ms\tremaining: 4.22s\n",
      "78:\tlearn: 74.5327804\ttotal: 361ms\tremaining: 4.21s\n",
      "79:\tlearn: 74.2050025\ttotal: 364ms\tremaining: 4.19s\n",
      "80:\tlearn: 73.8816205\ttotal: 368ms\tremaining: 4.18s\n",
      "81:\tlearn: 73.5705141\ttotal: 372ms\tremaining: 4.17s\n",
      "82:\tlearn: 73.2753563\ttotal: 376ms\tremaining: 4.15s\n",
      "83:\tlearn: 73.1144493\ttotal: 379ms\tremaining: 4.13s\n",
      "84:\tlearn: 72.9827401\ttotal: 383ms\tremaining: 4.12s\n",
      "85:\tlearn: 72.9131152\ttotal: 386ms\tremaining: 4.11s\n",
      "86:\tlearn: 72.8391437\ttotal: 390ms\tremaining: 4.1s\n",
      "87:\tlearn: 72.6920175\ttotal: 393ms\tremaining: 4.08s\n",
      "88:\tlearn: 72.4405522\ttotal: 396ms\tremaining: 4.06s\n",
      "89:\tlearn: 72.2075243\ttotal: 399ms\tremaining: 4.04s\n",
      "90:\tlearn: 72.0006799\ttotal: 403ms\tremaining: 4.02s\n",
      "91:\tlearn: 71.7510116\ttotal: 406ms\tremaining: 4.01s\n",
      "92:\tlearn: 71.5335895\ttotal: 410ms\tremaining: 4s\n",
      "93:\tlearn: 71.3007383\ttotal: 414ms\tremaining: 3.99s\n",
      "94:\tlearn: 71.1839827\ttotal: 417ms\tremaining: 3.97s\n",
      "95:\tlearn: 70.9708106\ttotal: 421ms\tremaining: 3.96s\n",
      "96:\tlearn: 70.8425731\ttotal: 424ms\tremaining: 3.94s\n",
      "97:\tlearn: 70.7279643\ttotal: 427ms\tremaining: 3.93s\n",
      "98:\tlearn: 70.5330735\ttotal: 430ms\tremaining: 3.92s\n",
      "99:\tlearn: 70.3441269\ttotal: 434ms\tremaining: 3.9s\n",
      "100:\tlearn: 70.1812052\ttotal: 437ms\tremaining: 3.89s\n",
      "101:\tlearn: 70.0400611\ttotal: 441ms\tremaining: 3.88s\n",
      "102:\tlearn: 69.8984188\ttotal: 444ms\tremaining: 3.87s\n",
      "103:\tlearn: 69.7381516\ttotal: 447ms\tremaining: 3.85s\n",
      "104:\tlearn: 69.5831770\ttotal: 453ms\tremaining: 3.86s\n",
      "105:\tlearn: 69.4936110\ttotal: 459ms\tremaining: 3.87s\n",
      "106:\tlearn: 69.3058346\ttotal: 466ms\tremaining: 3.89s\n",
      "107:\tlearn: 69.2214369\ttotal: 471ms\tremaining: 3.89s\n",
      "108:\tlearn: 69.1344149\ttotal: 479ms\tremaining: 3.92s\n",
      "109:\tlearn: 69.0608346\ttotal: 484ms\tremaining: 3.92s\n",
      "110:\tlearn: 68.9833902\ttotal: 488ms\tremaining: 3.9s\n",
      "111:\tlearn: 68.8952251\ttotal: 493ms\tremaining: 3.91s\n",
      "112:\tlearn: 68.7548886\ttotal: 496ms\tremaining: 3.9s\n",
      "113:\tlearn: 68.6963780\ttotal: 500ms\tremaining: 3.89s\n",
      "114:\tlearn: 68.5613572\ttotal: 503ms\tremaining: 3.87s\n",
      "115:\tlearn: 68.4709167\ttotal: 509ms\tremaining: 3.88s\n",
      "116:\tlearn: 68.3899945\ttotal: 513ms\tremaining: 3.87s\n",
      "117:\tlearn: 68.3591386\ttotal: 516ms\tremaining: 3.86s\n",
      "118:\tlearn: 68.2753298\ttotal: 520ms\tremaining: 3.85s\n",
      "119:\tlearn: 68.1293593\ttotal: 525ms\tremaining: 3.85s\n",
      "120:\tlearn: 68.0005852\ttotal: 528ms\tremaining: 3.84s\n",
      "121:\tlearn: 67.8752213\ttotal: 532ms\tremaining: 3.83s\n",
      "122:\tlearn: 67.8344750\ttotal: 535ms\tremaining: 3.81s\n",
      "123:\tlearn: 67.7890142\ttotal: 540ms\tremaining: 3.82s\n",
      "124:\tlearn: 67.7633455\ttotal: 544ms\tremaining: 3.81s\n",
      "125:\tlearn: 67.6597139\ttotal: 548ms\tremaining: 3.8s\n",
      "126:\tlearn: 67.6268668\ttotal: 551ms\tremaining: 3.79s\n",
      "127:\tlearn: 67.5209834\ttotal: 555ms\tremaining: 3.78s\n",
      "128:\tlearn: 67.4053109\ttotal: 559ms\tremaining: 3.77s\n",
      "129:\tlearn: 67.3586504\ttotal: 562ms\tremaining: 3.76s\n",
      "130:\tlearn: 67.2952223\ttotal: 566ms\tremaining: 3.75s\n",
      "131:\tlearn: 67.1828082\ttotal: 569ms\tremaining: 3.74s\n",
      "132:\tlearn: 67.0941994\ttotal: 574ms\tremaining: 3.74s\n",
      "133:\tlearn: 67.0581532\ttotal: 577ms\tremaining: 3.73s\n",
      "134:\tlearn: 67.0207556\ttotal: 581ms\tremaining: 3.72s\n",
      "135:\tlearn: 66.9809504\ttotal: 585ms\tremaining: 3.71s\n",
      "136:\tlearn: 66.8941102\ttotal: 589ms\tremaining: 3.71s\n",
      "137:\tlearn: 66.8127555\ttotal: 593ms\tremaining: 3.7s\n",
      "138:\tlearn: 66.7731275\ttotal: 597ms\tremaining: 3.7s\n",
      "139:\tlearn: 66.7372839\ttotal: 601ms\tremaining: 3.69s\n",
      "140:\tlearn: 66.6539030\ttotal: 605ms\tremaining: 3.69s\n",
      "141:\tlearn: 66.6200521\ttotal: 609ms\tremaining: 3.68s\n",
      "142:\tlearn: 66.4878230\ttotal: 613ms\tremaining: 3.67s\n",
      "143:\tlearn: 66.4101892\ttotal: 617ms\tremaining: 3.67s\n",
      "144:\tlearn: 66.3653271\ttotal: 622ms\tremaining: 3.67s\n",
      "145:\tlearn: 66.2967727\ttotal: 625ms\tremaining: 3.66s\n",
      "146:\tlearn: 66.2712109\ttotal: 629ms\tremaining: 3.65s\n",
      "147:\tlearn: 66.2388584\ttotal: 633ms\tremaining: 3.64s\n",
      "148:\tlearn: 66.1865365\ttotal: 638ms\tremaining: 3.64s\n",
      "149:\tlearn: 66.1346745\ttotal: 643ms\tremaining: 3.64s\n",
      "150:\tlearn: 66.0666786\ttotal: 649ms\tremaining: 3.65s\n",
      "151:\tlearn: 66.0311414\ttotal: 656ms\tremaining: 3.66s\n",
      "152:\tlearn: 66.0135714\ttotal: 662ms\tremaining: 3.67s\n",
      "153:\tlearn: 65.9745408\ttotal: 669ms\tremaining: 3.67s\n",
      "154:\tlearn: 65.9448757\ttotal: 676ms\tremaining: 3.69s\n",
      "155:\tlearn: 65.9042210\ttotal: 682ms\tremaining: 3.69s\n",
      "156:\tlearn: 65.8589833\ttotal: 688ms\tremaining: 3.69s\n",
      "157:\tlearn: 65.8420969\ttotal: 693ms\tremaining: 3.69s\n",
      "158:\tlearn: 65.7488329\ttotal: 700ms\tremaining: 3.7s\n",
      "159:\tlearn: 65.6659291\ttotal: 704ms\tremaining: 3.7s\n",
      "160:\tlearn: 65.5880889\ttotal: 708ms\tremaining: 3.69s\n",
      "161:\tlearn: 65.5078968\ttotal: 711ms\tremaining: 3.68s\n",
      "162:\tlearn: 65.4329408\ttotal: 715ms\tremaining: 3.67s\n",
      "163:\tlearn: 65.4222610\ttotal: 720ms\tremaining: 3.67s\n",
      "164:\tlearn: 65.3600702\ttotal: 723ms\tremaining: 3.66s\n",
      "165:\tlearn: 65.3325730\ttotal: 727ms\tremaining: 3.65s\n",
      "166:\tlearn: 65.3090610\ttotal: 732ms\tremaining: 3.65s\n",
      "167:\tlearn: 65.3005109\ttotal: 735ms\tremaining: 3.64s\n",
      "168:\tlearn: 65.1778525\ttotal: 738ms\tremaining: 3.63s\n",
      "169:\tlearn: 65.1556588\ttotal: 742ms\tremaining: 3.62s\n",
      "170:\tlearn: 65.1095561\ttotal: 745ms\tremaining: 3.61s\n",
      "171:\tlearn: 65.0935450\ttotal: 749ms\tremaining: 3.61s\n",
      "172:\tlearn: 65.0332620\ttotal: 753ms\tremaining: 3.6s\n",
      "173:\tlearn: 65.0112746\ttotal: 757ms\tremaining: 3.59s\n",
      "174:\tlearn: 64.9561489\ttotal: 760ms\tremaining: 3.58s\n",
      "175:\tlearn: 64.8940148\ttotal: 764ms\tremaining: 3.57s\n",
      "176:\tlearn: 64.8597117\ttotal: 767ms\tremaining: 3.56s\n",
      "177:\tlearn: 64.7897903\ttotal: 770ms\tremaining: 3.56s\n",
      "178:\tlearn: 64.7693385\ttotal: 774ms\tremaining: 3.55s\n",
      "179:\tlearn: 64.7460143\ttotal: 777ms\tremaining: 3.54s\n",
      "180:\tlearn: 64.7302430\ttotal: 781ms\tremaining: 3.53s\n",
      "181:\tlearn: 64.6585603\ttotal: 784ms\tremaining: 3.52s\n",
      "182:\tlearn: 64.6364471\ttotal: 789ms\tremaining: 3.52s\n",
      "183:\tlearn: 64.6075512\ttotal: 792ms\tremaining: 3.51s\n",
      "184:\tlearn: 64.5938832\ttotal: 796ms\tremaining: 3.5s\n",
      "185:\tlearn: 64.5364513\ttotal: 799ms\tremaining: 3.5s\n",
      "186:\tlearn: 64.4183337\ttotal: 802ms\tremaining: 3.49s\n",
      "187:\tlearn: 64.3621600\ttotal: 806ms\tremaining: 3.48s\n",
      "188:\tlearn: 64.3496473\ttotal: 809ms\tremaining: 3.47s\n",
      "189:\tlearn: 64.3328140\ttotal: 813ms\tremaining: 3.47s\n",
      "190:\tlearn: 64.2825264\ttotal: 817ms\tremaining: 3.46s\n",
      "191:\tlearn: 64.2397382\ttotal: 820ms\tremaining: 3.45s\n",
      "192:\tlearn: 64.2239759\ttotal: 825ms\tremaining: 3.45s\n",
      "193:\tlearn: 64.1996454\ttotal: 829ms\tremaining: 3.44s\n",
      "194:\tlearn: 64.1457137\ttotal: 832ms\tremaining: 3.43s\n",
      "195:\tlearn: 64.1316343\ttotal: 836ms\tremaining: 3.43s\n",
      "196:\tlearn: 64.1093544\ttotal: 843ms\tremaining: 3.43s\n",
      "197:\tlearn: 64.0780241\ttotal: 849ms\tremaining: 3.44s\n",
      "198:\tlearn: 64.0673071\ttotal: 855ms\tremaining: 3.44s\n",
      "199:\tlearn: 64.0078308\ttotal: 861ms\tremaining: 3.44s\n",
      "200:\tlearn: 63.9966980\ttotal: 864ms\tremaining: 3.44s\n",
      "201:\tlearn: 63.9629871\ttotal: 868ms\tremaining: 3.43s\n",
      "202:\tlearn: 63.9506222\ttotal: 871ms\tremaining: 3.42s\n",
      "203:\tlearn: 63.9241911\ttotal: 876ms\tremaining: 3.42s\n",
      "204:\tlearn: 63.8935738\ttotal: 880ms\tremaining: 3.41s\n",
      "205:\tlearn: 63.8248548\ttotal: 884ms\tremaining: 3.41s\n",
      "206:\tlearn: 63.8085295\ttotal: 887ms\tremaining: 3.4s\n",
      "207:\tlearn: 63.7929116\ttotal: 891ms\tremaining: 3.39s\n",
      "208:\tlearn: 63.7711580\ttotal: 895ms\tremaining: 3.38s\n",
      "209:\tlearn: 63.7570657\ttotal: 899ms\tremaining: 3.38s\n",
      "210:\tlearn: 63.7273025\ttotal: 903ms\tremaining: 3.38s\n",
      "211:\tlearn: 63.7195537\ttotal: 906ms\tremaining: 3.37s\n",
      "212:\tlearn: 63.7157212\ttotal: 910ms\tremaining: 3.36s\n",
      "213:\tlearn: 63.6834430\ttotal: 914ms\tremaining: 3.35s\n",
      "214:\tlearn: 63.6539294\ttotal: 918ms\tremaining: 3.35s\n",
      "215:\tlearn: 63.6503513\ttotal: 921ms\tremaining: 3.34s\n",
      "216:\tlearn: 63.6351900\ttotal: 925ms\tremaining: 3.34s\n",
      "217:\tlearn: 63.6155187\ttotal: 929ms\tremaining: 3.33s\n",
      "218:\tlearn: 63.5997472\ttotal: 933ms\tremaining: 3.33s\n",
      "219:\tlearn: 63.5737137\ttotal: 937ms\tremaining: 3.32s\n",
      "220:\tlearn: 63.5604291\ttotal: 943ms\tremaining: 3.32s\n",
      "221:\tlearn: 63.5563318\ttotal: 949ms\tremaining: 3.33s\n",
      "222:\tlearn: 63.5001688\ttotal: 957ms\tremaining: 3.33s\n",
      "223:\tlearn: 63.4773688\ttotal: 964ms\tremaining: 3.34s\n",
      "224:\tlearn: 63.4679304\ttotal: 969ms\tremaining: 3.34s\n",
      "225:\tlearn: 63.4444309\ttotal: 974ms\tremaining: 3.33s\n",
      "226:\tlearn: 63.3985054\ttotal: 979ms\tremaining: 3.33s\n",
      "227:\tlearn: 63.3817640\ttotal: 982ms\tremaining: 3.33s\n",
      "228:\tlearn: 63.3699063\ttotal: 991ms\tremaining: 3.34s\n",
      "229:\tlearn: 63.3466553\ttotal: 998ms\tremaining: 3.34s\n",
      "230:\tlearn: 63.3436030\ttotal: 1.01s\tremaining: 3.35s\n",
      "231:\tlearn: 63.3231557\ttotal: 1.01s\tremaining: 3.35s\n",
      "232:\tlearn: 63.2862849\ttotal: 1.03s\tremaining: 3.38s\n",
      "233:\tlearn: 63.2677279\ttotal: 1.03s\tremaining: 3.38s\n",
      "234:\tlearn: 63.2556795\ttotal: 1.04s\tremaining: 3.39s\n",
      "235:\tlearn: 63.2473905\ttotal: 1.05s\tremaining: 3.39s\n",
      "236:\tlearn: 63.2360440\ttotal: 1.06s\tremaining: 3.4s\n",
      "237:\tlearn: 63.2090404\ttotal: 1.06s\tremaining: 3.4s\n",
      "238:\tlearn: 63.2058237\ttotal: 1.07s\tremaining: 3.4s\n",
      "239:\tlearn: 63.1969625\ttotal: 1.07s\tremaining: 3.4s\n",
      "240:\tlearn: 63.1618508\ttotal: 1.08s\tremaining: 3.4s\n",
      "241:\tlearn: 63.1391276\ttotal: 1.08s\tremaining: 3.4s\n",
      "242:\tlearn: 63.1319574\ttotal: 1.09s\tremaining: 3.39s\n",
      "243:\tlearn: 63.1126611\ttotal: 1.09s\tremaining: 3.39s\n",
      "244:\tlearn: 63.1033571\ttotal: 1.1s\tremaining: 3.39s\n",
      "245:\tlearn: 63.0526086\ttotal: 1.1s\tremaining: 3.39s\n",
      "246:\tlearn: 63.0382274\ttotal: 1.11s\tremaining: 3.39s\n",
      "247:\tlearn: 63.0340952\ttotal: 1.12s\tremaining: 3.39s\n",
      "248:\tlearn: 63.0278756\ttotal: 1.13s\tremaining: 3.4s\n",
      "249:\tlearn: 62.9049202\ttotal: 1.13s\tremaining: 3.39s\n",
      "250:\tlearn: 62.8772989\ttotal: 1.14s\tremaining: 3.4s\n",
      "251:\tlearn: 62.8696563\ttotal: 1.15s\tremaining: 3.42s\n",
      "252:\tlearn: 62.8543005\ttotal: 1.17s\tremaining: 3.44s\n",
      "253:\tlearn: 62.8129793\ttotal: 1.17s\tremaining: 3.44s\n",
      "254:\tlearn: 62.7583464\ttotal: 1.18s\tremaining: 3.45s\n",
      "255:\tlearn: 62.7289261\ttotal: 1.19s\tremaining: 3.46s\n",
      "256:\tlearn: 62.6996161\ttotal: 1.2s\tremaining: 3.46s\n",
      "257:\tlearn: 62.6888792\ttotal: 1.2s\tremaining: 3.45s\n",
      "258:\tlearn: 62.6801337\ttotal: 1.21s\tremaining: 3.45s\n",
      "259:\tlearn: 62.6726218\ttotal: 1.21s\tremaining: 3.46s\n",
      "260:\tlearn: 62.6620784\ttotal: 1.22s\tremaining: 3.46s\n",
      "261:\tlearn: 62.6467034\ttotal: 1.23s\tremaining: 3.46s\n",
      "262:\tlearn: 62.6266244\ttotal: 1.23s\tremaining: 3.46s\n",
      "263:\tlearn: 62.6182612\ttotal: 1.24s\tremaining: 3.45s\n",
      "264:\tlearn: 62.6014715\ttotal: 1.24s\tremaining: 3.44s\n",
      "265:\tlearn: 62.5347285\ttotal: 1.25s\tremaining: 3.44s\n",
      "266:\tlearn: 62.5234035\ttotal: 1.25s\tremaining: 3.43s\n",
      "267:\tlearn: 62.4847279\ttotal: 1.25s\tremaining: 3.42s\n",
      "268:\tlearn: 62.4656022\ttotal: 1.26s\tremaining: 3.42s\n",
      "269:\tlearn: 62.4527568\ttotal: 1.26s\tremaining: 3.41s\n",
      "270:\tlearn: 62.4378992\ttotal: 1.26s\tremaining: 3.4s\n",
      "271:\tlearn: 62.3236278\ttotal: 1.27s\tremaining: 3.4s\n",
      "272:\tlearn: 62.3143692\ttotal: 1.27s\tremaining: 3.39s\n",
      "273:\tlearn: 62.2951468\ttotal: 1.28s\tremaining: 3.38s\n",
      "274:\tlearn: 62.2642881\ttotal: 1.28s\tremaining: 3.38s\n",
      "275:\tlearn: 62.2466548\ttotal: 1.28s\tremaining: 3.37s\n",
      "276:\tlearn: 62.2158244\ttotal: 1.29s\tremaining: 3.37s\n",
      "277:\tlearn: 62.1949706\ttotal: 1.29s\tremaining: 3.36s\n",
      "278:\tlearn: 62.1742797\ttotal: 1.3s\tremaining: 3.35s\n",
      "279:\tlearn: 62.1721235\ttotal: 1.3s\tremaining: 3.35s\n",
      "280:\tlearn: 62.1652389\ttotal: 1.3s\tremaining: 3.34s\n",
      "281:\tlearn: 62.1600775\ttotal: 1.31s\tremaining: 3.34s\n",
      "282:\tlearn: 62.1532684\ttotal: 1.31s\tremaining: 3.33s\n",
      "283:\tlearn: 62.1271164\ttotal: 1.32s\tremaining: 3.32s\n",
      "284:\tlearn: 62.1203898\ttotal: 1.32s\tremaining: 3.32s\n",
      "285:\tlearn: 62.1055305\ttotal: 1.33s\tremaining: 3.31s\n",
      "286:\tlearn: 62.0877253\ttotal: 1.33s\tremaining: 3.3s\n",
      "287:\tlearn: 62.0334897\ttotal: 1.33s\tremaining: 3.3s\n",
      "288:\tlearn: 62.0072966\ttotal: 1.34s\tremaining: 3.29s\n",
      "289:\tlearn: 61.9897318\ttotal: 1.34s\tremaining: 3.28s\n",
      "290:\tlearn: 61.9826023\ttotal: 1.34s\tremaining: 3.28s\n",
      "291:\tlearn: 61.9787071\ttotal: 1.35s\tremaining: 3.27s\n",
      "292:\tlearn: 61.9733947\ttotal: 1.35s\tremaining: 3.27s\n",
      "293:\tlearn: 61.9667440\ttotal: 1.36s\tremaining: 3.26s\n",
      "294:\tlearn: 61.9506601\ttotal: 1.36s\tremaining: 3.25s\n",
      "295:\tlearn: 61.9124708\ttotal: 1.36s\tremaining: 3.25s\n",
      "296:\tlearn: 61.8923053\ttotal: 1.37s\tremaining: 3.24s\n",
      "297:\tlearn: 61.8450981\ttotal: 1.37s\tremaining: 3.23s\n",
      "298:\tlearn: 61.8331975\ttotal: 1.38s\tremaining: 3.23s\n",
      "299:\tlearn: 61.8098055\ttotal: 1.38s\tremaining: 3.22s\n",
      "300:\tlearn: 61.8024061\ttotal: 1.38s\tremaining: 3.21s\n",
      "301:\tlearn: 61.7958340\ttotal: 1.39s\tremaining: 3.21s\n",
      "302:\tlearn: 61.7931630\ttotal: 1.4s\tremaining: 3.21s\n",
      "303:\tlearn: 61.7719385\ttotal: 1.4s\tremaining: 3.21s\n",
      "304:\tlearn: 61.7500033\ttotal: 1.41s\tremaining: 3.21s\n",
      "305:\tlearn: 61.7460391\ttotal: 1.41s\tremaining: 3.2s\n",
      "306:\tlearn: 61.7408714\ttotal: 1.42s\tremaining: 3.2s\n",
      "307:\tlearn: 61.7283355\ttotal: 1.42s\tremaining: 3.19s\n",
      "308:\tlearn: 61.7250802\ttotal: 1.43s\tremaining: 3.19s\n",
      "309:\tlearn: 61.6936023\ttotal: 1.44s\tremaining: 3.2s\n",
      "310:\tlearn: 61.6400738\ttotal: 1.44s\tremaining: 3.19s\n",
      "311:\tlearn: 61.6257821\ttotal: 1.45s\tremaining: 3.19s\n",
      "312:\tlearn: 61.6191170\ttotal: 1.45s\tremaining: 3.18s\n",
      "313:\tlearn: 61.6102147\ttotal: 1.46s\tremaining: 3.18s\n",
      "314:\tlearn: 61.6054884\ttotal: 1.46s\tremaining: 3.17s\n",
      "315:\tlearn: 61.5926020\ttotal: 1.47s\tremaining: 3.17s\n",
      "316:\tlearn: 61.5707568\ttotal: 1.47s\tremaining: 3.17s\n",
      "317:\tlearn: 61.5519176\ttotal: 1.47s\tremaining: 3.16s\n",
      "318:\tlearn: 61.5388223\ttotal: 1.48s\tremaining: 3.15s\n",
      "319:\tlearn: 61.5315449\ttotal: 1.48s\tremaining: 3.15s\n",
      "320:\tlearn: 61.5078896\ttotal: 1.49s\tremaining: 3.14s\n",
      "321:\tlearn: 61.5010044\ttotal: 1.49s\tremaining: 3.13s\n",
      "322:\tlearn: 61.4920324\ttotal: 1.49s\tremaining: 3.13s\n",
      "323:\tlearn: 61.4852260\ttotal: 1.5s\tremaining: 3.12s\n",
      "324:\tlearn: 61.4676030\ttotal: 1.5s\tremaining: 3.12s\n",
      "325:\tlearn: 61.4658446\ttotal: 1.5s\tremaining: 3.11s\n",
      "326:\tlearn: 61.4523519\ttotal: 1.51s\tremaining: 3.1s\n",
      "327:\tlearn: 61.4365046\ttotal: 1.51s\tremaining: 3.1s\n",
      "328:\tlearn: 61.4303286\ttotal: 1.52s\tremaining: 3.09s\n",
      "329:\tlearn: 61.4260396\ttotal: 1.52s\tremaining: 3.09s\n",
      "330:\tlearn: 61.3975625\ttotal: 1.52s\tremaining: 3.08s\n",
      "331:\tlearn: 61.3946694\ttotal: 1.53s\tremaining: 3.07s\n",
      "332:\tlearn: 61.3857912\ttotal: 1.53s\tremaining: 3.07s\n",
      "333:\tlearn: 61.3712008\ttotal: 1.53s\tremaining: 3.06s\n",
      "334:\tlearn: 61.3498682\ttotal: 1.54s\tremaining: 3.06s\n",
      "335:\tlearn: 61.3207169\ttotal: 1.54s\tremaining: 3.05s\n",
      "336:\tlearn: 61.3153304\ttotal: 1.55s\tremaining: 3.04s\n",
      "337:\tlearn: 61.2805012\ttotal: 1.55s\tremaining: 3.04s\n",
      "338:\tlearn: 61.2722980\ttotal: 1.55s\tremaining: 3.03s\n",
      "339:\tlearn: 61.2569238\ttotal: 1.56s\tremaining: 3.02s\n",
      "340:\tlearn: 61.2424294\ttotal: 1.56s\tremaining: 3.02s\n",
      "341:\tlearn: 61.2314874\ttotal: 1.56s\tremaining: 3.01s\n",
      "342:\tlearn: 61.2264191\ttotal: 1.57s\tremaining: 3.01s\n",
      "343:\tlearn: 61.2125042\ttotal: 1.57s\tremaining: 3s\n",
      "344:\tlearn: 61.2072122\ttotal: 1.58s\tremaining: 3s\n",
      "345:\tlearn: 61.1973554\ttotal: 1.59s\tremaining: 3s\n",
      "346:\tlearn: 61.1830898\ttotal: 1.59s\tremaining: 3s\n",
      "347:\tlearn: 61.1662110\ttotal: 1.6s\tremaining: 2.99s\n",
      "348:\tlearn: 61.1561888\ttotal: 1.6s\tremaining: 2.99s\n",
      "349:\tlearn: 61.1532041\ttotal: 1.61s\tremaining: 2.99s\n",
      "350:\tlearn: 61.1267117\ttotal: 1.62s\tremaining: 2.99s\n",
      "351:\tlearn: 61.1190064\ttotal: 1.62s\tremaining: 2.98s\n",
      "352:\tlearn: 61.0890225\ttotal: 1.62s\tremaining: 2.98s\n",
      "353:\tlearn: 61.0787834\ttotal: 1.63s\tremaining: 2.98s\n",
      "354:\tlearn: 61.0442425\ttotal: 1.64s\tremaining: 2.98s\n",
      "355:\tlearn: 61.0371809\ttotal: 1.65s\tremaining: 2.98s\n",
      "356:\tlearn: 61.0268515\ttotal: 1.65s\tremaining: 2.98s\n",
      "357:\tlearn: 61.0229974\ttotal: 1.66s\tremaining: 2.98s\n",
      "358:\tlearn: 60.9984715\ttotal: 1.67s\tremaining: 2.97s\n",
      "359:\tlearn: 60.9585285\ttotal: 1.67s\tremaining: 2.97s\n",
      "360:\tlearn: 60.9492411\ttotal: 1.68s\tremaining: 2.97s\n",
      "361:\tlearn: 60.9440854\ttotal: 1.68s\tremaining: 2.97s\n",
      "362:\tlearn: 60.9308245\ttotal: 1.69s\tremaining: 2.96s\n",
      "363:\tlearn: 60.9179827\ttotal: 1.69s\tremaining: 2.96s\n",
      "364:\tlearn: 60.9045427\ttotal: 1.7s\tremaining: 2.96s\n",
      "365:\tlearn: 60.8698203\ttotal: 1.71s\tremaining: 2.95s\n",
      "366:\tlearn: 60.8567756\ttotal: 1.71s\tremaining: 2.95s\n",
      "367:\tlearn: 60.8425172\ttotal: 1.71s\tremaining: 2.94s\n",
      "368:\tlearn: 60.8056192\ttotal: 1.72s\tremaining: 2.94s\n",
      "369:\tlearn: 60.7895624\ttotal: 1.72s\tremaining: 2.93s\n",
      "370:\tlearn: 60.7827460\ttotal: 1.73s\tremaining: 2.93s\n",
      "371:\tlearn: 60.7760441\ttotal: 1.73s\tremaining: 2.92s\n",
      "372:\tlearn: 60.7609933\ttotal: 1.73s\tremaining: 2.92s\n",
      "373:\tlearn: 60.7563470\ttotal: 1.74s\tremaining: 2.91s\n",
      "374:\tlearn: 60.7451623\ttotal: 1.74s\tremaining: 2.9s\n",
      "375:\tlearn: 60.7357872\ttotal: 1.75s\tremaining: 2.9s\n",
      "376:\tlearn: 60.7268020\ttotal: 1.75s\tremaining: 2.89s\n",
      "377:\tlearn: 60.7222832\ttotal: 1.76s\tremaining: 2.89s\n",
      "378:\tlearn: 60.7118821\ttotal: 1.76s\tremaining: 2.89s\n",
      "379:\tlearn: 60.7064312\ttotal: 1.77s\tremaining: 2.88s\n",
      "380:\tlearn: 60.6938258\ttotal: 1.77s\tremaining: 2.88s\n",
      "381:\tlearn: 60.6841872\ttotal: 1.77s\tremaining: 2.87s\n",
      "382:\tlearn: 60.6778632\ttotal: 1.78s\tremaining: 2.87s\n",
      "383:\tlearn: 60.6663862\ttotal: 1.78s\tremaining: 2.86s\n",
      "384:\tlearn: 60.6613941\ttotal: 1.79s\tremaining: 2.87s\n",
      "385:\tlearn: 60.6544098\ttotal: 1.8s\tremaining: 2.87s\n",
      "386:\tlearn: 60.6380220\ttotal: 1.81s\tremaining: 2.87s\n",
      "387:\tlearn: 60.6302739\ttotal: 1.82s\tremaining: 2.87s\n",
      "388:\tlearn: 60.6203328\ttotal: 1.82s\tremaining: 2.86s\n",
      "389:\tlearn: 60.6019963\ttotal: 1.82s\tremaining: 2.85s\n",
      "390:\tlearn: 60.5988241\ttotal: 1.83s\tremaining: 2.85s\n",
      "391:\tlearn: 60.5681732\ttotal: 1.83s\tremaining: 2.85s\n",
      "392:\tlearn: 60.5659246\ttotal: 1.84s\tremaining: 2.84s\n",
      "393:\tlearn: 60.5598823\ttotal: 1.84s\tremaining: 2.84s\n",
      "394:\tlearn: 60.5582415\ttotal: 1.85s\tremaining: 2.83s\n",
      "395:\tlearn: 60.5470989\ttotal: 1.85s\tremaining: 2.82s\n",
      "396:\tlearn: 60.5139512\ttotal: 1.85s\tremaining: 2.82s\n",
      "397:\tlearn: 60.5044880\ttotal: 1.86s\tremaining: 2.81s\n",
      "398:\tlearn: 60.4941439\ttotal: 1.86s\tremaining: 2.81s\n",
      "399:\tlearn: 60.4783841\ttotal: 1.87s\tremaining: 2.81s\n",
      "400:\tlearn: 60.4641044\ttotal: 1.88s\tremaining: 2.81s\n",
      "401:\tlearn: 60.4583765\ttotal: 1.89s\tremaining: 2.81s\n",
      "402:\tlearn: 60.4510361\ttotal: 1.89s\tremaining: 2.8s\n",
      "403:\tlearn: 60.4434504\ttotal: 1.9s\tremaining: 2.8s\n",
      "404:\tlearn: 60.4359343\ttotal: 1.9s\tremaining: 2.79s\n",
      "405:\tlearn: 60.4242755\ttotal: 1.91s\tremaining: 2.79s\n",
      "406:\tlearn: 60.4231996\ttotal: 1.91s\tremaining: 2.78s\n",
      "407:\tlearn: 60.4166565\ttotal: 1.91s\tremaining: 2.78s\n",
      "408:\tlearn: 60.3825392\ttotal: 1.92s\tremaining: 2.77s\n",
      "409:\tlearn: 60.3537022\ttotal: 1.92s\tremaining: 2.77s\n",
      "410:\tlearn: 60.3420668\ttotal: 1.93s\tremaining: 2.76s\n",
      "411:\tlearn: 60.3159418\ttotal: 1.93s\tremaining: 2.76s\n",
      "412:\tlearn: 60.2876507\ttotal: 1.94s\tremaining: 2.75s\n",
      "413:\tlearn: 60.2630466\ttotal: 1.94s\tremaining: 2.75s\n",
      "414:\tlearn: 60.2287690\ttotal: 1.95s\tremaining: 2.74s\n",
      "415:\tlearn: 60.1635891\ttotal: 1.95s\tremaining: 2.74s\n",
      "416:\tlearn: 60.1606819\ttotal: 1.95s\tremaining: 2.73s\n",
      "417:\tlearn: 60.1482470\ttotal: 1.96s\tremaining: 2.73s\n",
      "418:\tlearn: 60.1293201\ttotal: 1.97s\tremaining: 2.73s\n",
      "419:\tlearn: 60.1056432\ttotal: 1.97s\tremaining: 2.72s\n",
      "420:\tlearn: 60.0968108\ttotal: 1.97s\tremaining: 2.71s\n",
      "421:\tlearn: 60.0873319\ttotal: 1.98s\tremaining: 2.71s\n",
      "422:\tlearn: 60.0639365\ttotal: 1.98s\tremaining: 2.71s\n",
      "423:\tlearn: 60.0544864\ttotal: 1.99s\tremaining: 2.7s\n",
      "424:\tlearn: 60.0408812\ttotal: 1.99s\tremaining: 2.7s\n",
      "425:\tlearn: 60.0300464\ttotal: 2s\tremaining: 2.7s\n",
      "426:\tlearn: 60.0230177\ttotal: 2.01s\tremaining: 2.7s\n",
      "427:\tlearn: 60.0046861\ttotal: 2.02s\tremaining: 2.7s\n",
      "428:\tlearn: 60.0037635\ttotal: 2.02s\tremaining: 2.69s\n",
      "429:\tlearn: 59.9964128\ttotal: 2.03s\tremaining: 2.69s\n",
      "430:\tlearn: 59.9849508\ttotal: 2.03s\tremaining: 2.69s\n",
      "431:\tlearn: 59.9778794\ttotal: 2.04s\tremaining: 2.68s\n",
      "432:\tlearn: 59.9765977\ttotal: 2.04s\tremaining: 2.68s\n",
      "433:\tlearn: 59.9686770\ttotal: 2.05s\tremaining: 2.67s\n",
      "434:\tlearn: 59.9470954\ttotal: 2.05s\tremaining: 2.67s\n",
      "435:\tlearn: 59.9450429\ttotal: 2.06s\tremaining: 2.66s\n",
      "436:\tlearn: 59.9396491\ttotal: 2.06s\tremaining: 2.66s\n",
      "437:\tlearn: 59.9185046\ttotal: 2.07s\tremaining: 2.65s\n",
      "438:\tlearn: 59.9080478\ttotal: 2.07s\tremaining: 2.65s\n",
      "439:\tlearn: 59.8848348\ttotal: 2.08s\tremaining: 2.64s\n",
      "440:\tlearn: 59.8595419\ttotal: 2.08s\tremaining: 2.64s\n",
      "441:\tlearn: 59.8329125\ttotal: 2.08s\tremaining: 2.63s\n",
      "442:\tlearn: 59.8275649\ttotal: 2.09s\tremaining: 2.63s\n",
      "443:\tlearn: 59.8201424\ttotal: 2.1s\tremaining: 2.63s\n",
      "444:\tlearn: 59.8151752\ttotal: 2.1s\tremaining: 2.62s\n",
      "445:\tlearn: 59.7806220\ttotal: 2.11s\tremaining: 2.62s\n",
      "446:\tlearn: 59.7774452\ttotal: 2.11s\tremaining: 2.62s\n",
      "447:\tlearn: 59.7647747\ttotal: 2.12s\tremaining: 2.61s\n",
      "448:\tlearn: 59.7589538\ttotal: 2.12s\tremaining: 2.61s\n",
      "449:\tlearn: 59.7384212\ttotal: 2.13s\tremaining: 2.6s\n",
      "450:\tlearn: 59.7194065\ttotal: 2.13s\tremaining: 2.6s\n",
      "451:\tlearn: 59.6991540\ttotal: 2.14s\tremaining: 2.59s\n",
      "452:\tlearn: 59.6900507\ttotal: 2.14s\tremaining: 2.59s\n",
      "453:\tlearn: 59.6810299\ttotal: 2.15s\tremaining: 2.58s\n",
      "454:\tlearn: 59.6760485\ttotal: 2.15s\tremaining: 2.58s\n",
      "455:\tlearn: 59.6709035\ttotal: 2.16s\tremaining: 2.57s\n",
      "456:\tlearn: 59.6663451\ttotal: 2.16s\tremaining: 2.57s\n",
      "457:\tlearn: 59.6567713\ttotal: 2.17s\tremaining: 2.56s\n",
      "458:\tlearn: 59.6450437\ttotal: 2.17s\tremaining: 2.56s\n",
      "459:\tlearn: 59.6439344\ttotal: 2.17s\tremaining: 2.55s\n",
      "460:\tlearn: 59.6404065\ttotal: 2.18s\tremaining: 2.55s\n",
      "461:\tlearn: 59.6348846\ttotal: 2.19s\tremaining: 2.55s\n",
      "462:\tlearn: 59.6242882\ttotal: 2.19s\tremaining: 2.55s\n",
      "463:\tlearn: 59.6135834\ttotal: 2.2s\tremaining: 2.54s\n",
      "464:\tlearn: 59.6018798\ttotal: 2.21s\tremaining: 2.54s\n",
      "465:\tlearn: 59.6016362\ttotal: 2.21s\tremaining: 2.53s\n",
      "466:\tlearn: 59.5790276\ttotal: 2.22s\tremaining: 2.53s\n",
      "467:\tlearn: 59.5762934\ttotal: 2.22s\tremaining: 2.52s\n",
      "468:\tlearn: 59.5741592\ttotal: 2.23s\tremaining: 2.52s\n",
      "469:\tlearn: 59.5604470\ttotal: 2.23s\tremaining: 2.51s\n",
      "470:\tlearn: 59.5577427\ttotal: 2.23s\tremaining: 2.51s\n",
      "471:\tlearn: 59.5351051\ttotal: 2.24s\tremaining: 2.5s\n",
      "472:\tlearn: 59.5218994\ttotal: 2.24s\tremaining: 2.5s\n",
      "473:\tlearn: 59.5117733\ttotal: 2.24s\tremaining: 2.49s\n",
      "474:\tlearn: 59.5018090\ttotal: 2.25s\tremaining: 2.48s\n",
      "475:\tlearn: 59.4902043\ttotal: 2.25s\tremaining: 2.48s\n",
      "476:\tlearn: 59.4819134\ttotal: 2.26s\tremaining: 2.47s\n",
      "477:\tlearn: 59.4777664\ttotal: 2.26s\tremaining: 2.47s\n",
      "478:\tlearn: 59.4747949\ttotal: 2.26s\tremaining: 2.46s\n",
      "479:\tlearn: 59.4669390\ttotal: 2.27s\tremaining: 2.46s\n",
      "480:\tlearn: 59.4474219\ttotal: 2.27s\tremaining: 2.45s\n",
      "481:\tlearn: 59.4438895\ttotal: 2.27s\tremaining: 2.44s\n",
      "482:\tlearn: 59.4380185\ttotal: 2.28s\tremaining: 2.44s\n",
      "483:\tlearn: 59.4202182\ttotal: 2.28s\tremaining: 2.43s\n",
      "484:\tlearn: 59.4147777\ttotal: 2.29s\tremaining: 2.43s\n",
      "485:\tlearn: 59.3947831\ttotal: 2.29s\tremaining: 2.42s\n",
      "486:\tlearn: 59.3874614\ttotal: 2.29s\tremaining: 2.42s\n",
      "487:\tlearn: 59.3682492\ttotal: 2.3s\tremaining: 2.41s\n",
      "488:\tlearn: 59.3488907\ttotal: 2.3s\tremaining: 2.4s\n",
      "489:\tlearn: 59.3316648\ttotal: 2.3s\tremaining: 2.4s\n",
      "490:\tlearn: 59.3261978\ttotal: 2.31s\tremaining: 2.39s\n",
      "491:\tlearn: 59.3231056\ttotal: 2.31s\tremaining: 2.39s\n",
      "492:\tlearn: 59.3158297\ttotal: 2.31s\tremaining: 2.38s\n",
      "493:\tlearn: 59.3071511\ttotal: 2.32s\tremaining: 2.37s\n",
      "494:\tlearn: 59.3018424\ttotal: 2.32s\tremaining: 2.37s\n",
      "495:\tlearn: 59.2942228\ttotal: 2.33s\tremaining: 2.36s\n",
      "496:\tlearn: 59.2897651\ttotal: 2.33s\tremaining: 2.36s\n",
      "497:\tlearn: 59.2856232\ttotal: 2.33s\tremaining: 2.35s\n",
      "498:\tlearn: 59.2849018\ttotal: 2.34s\tremaining: 2.35s\n",
      "499:\tlearn: 59.2806204\ttotal: 2.34s\tremaining: 2.34s\n",
      "500:\tlearn: 59.2623462\ttotal: 2.35s\tremaining: 2.33s\n",
      "501:\tlearn: 59.2358753\ttotal: 2.35s\tremaining: 2.33s\n",
      "502:\tlearn: 59.2324700\ttotal: 2.35s\tremaining: 2.33s\n",
      "503:\tlearn: 59.2279971\ttotal: 2.36s\tremaining: 2.32s\n",
      "504:\tlearn: 59.2205495\ttotal: 2.36s\tremaining: 2.31s\n",
      "505:\tlearn: 59.2160023\ttotal: 2.37s\tremaining: 2.31s\n",
      "506:\tlearn: 59.2096457\ttotal: 2.37s\tremaining: 2.3s\n",
      "507:\tlearn: 59.2057476\ttotal: 2.37s\tremaining: 2.3s\n",
      "508:\tlearn: 59.1997239\ttotal: 2.38s\tremaining: 2.29s\n",
      "509:\tlearn: 59.1978097\ttotal: 2.38s\tremaining: 2.29s\n",
      "510:\tlearn: 59.1960124\ttotal: 2.39s\tremaining: 2.29s\n",
      "511:\tlearn: 59.1891606\ttotal: 2.4s\tremaining: 2.28s\n",
      "512:\tlearn: 59.1789725\ttotal: 2.4s\tremaining: 2.28s\n",
      "513:\tlearn: 59.1743341\ttotal: 2.4s\tremaining: 2.27s\n",
      "514:\tlearn: 59.1726929\ttotal: 2.41s\tremaining: 2.27s\n",
      "515:\tlearn: 59.1645182\ttotal: 2.41s\tremaining: 2.26s\n",
      "516:\tlearn: 59.1565272\ttotal: 2.42s\tremaining: 2.26s\n",
      "517:\tlearn: 59.1428307\ttotal: 2.42s\tremaining: 2.25s\n",
      "518:\tlearn: 59.1389879\ttotal: 2.42s\tremaining: 2.25s\n",
      "519:\tlearn: 59.1337241\ttotal: 2.43s\tremaining: 2.24s\n",
      "520:\tlearn: 59.1305013\ttotal: 2.43s\tremaining: 2.23s\n",
      "521:\tlearn: 59.1236877\ttotal: 2.44s\tremaining: 2.23s\n",
      "522:\tlearn: 59.1188312\ttotal: 2.44s\tremaining: 2.22s\n",
      "523:\tlearn: 59.1038210\ttotal: 2.44s\tremaining: 2.22s\n",
      "524:\tlearn: 59.0998398\ttotal: 2.45s\tremaining: 2.21s\n",
      "525:\tlearn: 59.0938800\ttotal: 2.45s\tremaining: 2.21s\n",
      "526:\tlearn: 59.0902759\ttotal: 2.46s\tremaining: 2.2s\n",
      "527:\tlearn: 59.0749806\ttotal: 2.46s\tremaining: 2.2s\n",
      "528:\tlearn: 59.0720862\ttotal: 2.46s\tremaining: 2.19s\n",
      "529:\tlearn: 59.0558226\ttotal: 2.47s\tremaining: 2.19s\n",
      "530:\tlearn: 59.0534070\ttotal: 2.47s\tremaining: 2.18s\n",
      "531:\tlearn: 59.0469098\ttotal: 2.48s\tremaining: 2.18s\n",
      "532:\tlearn: 59.0411565\ttotal: 2.48s\tremaining: 2.17s\n",
      "533:\tlearn: 59.0405379\ttotal: 2.48s\tremaining: 2.17s\n",
      "534:\tlearn: 59.0399507\ttotal: 2.49s\tremaining: 2.16s\n",
      "535:\tlearn: 59.0212097\ttotal: 2.49s\tremaining: 2.16s\n",
      "536:\tlearn: 59.0059804\ttotal: 2.49s\tremaining: 2.15s\n",
      "537:\tlearn: 59.0040032\ttotal: 2.5s\tremaining: 2.14s\n",
      "538:\tlearn: 59.0017467\ttotal: 2.5s\tremaining: 2.14s\n",
      "539:\tlearn: 58.9951837\ttotal: 2.51s\tremaining: 2.13s\n",
      "540:\tlearn: 58.9908841\ttotal: 2.51s\tremaining: 2.13s\n",
      "541:\tlearn: 58.9772812\ttotal: 2.51s\tremaining: 2.12s\n",
      "542:\tlearn: 58.9671737\ttotal: 2.52s\tremaining: 2.12s\n",
      "543:\tlearn: 58.9541569\ttotal: 2.52s\tremaining: 2.11s\n",
      "544:\tlearn: 58.9466677\ttotal: 2.52s\tremaining: 2.11s\n",
      "545:\tlearn: 58.9434288\ttotal: 2.53s\tremaining: 2.1s\n",
      "546:\tlearn: 58.9427637\ttotal: 2.53s\tremaining: 2.1s\n",
      "547:\tlearn: 58.9420815\ttotal: 2.54s\tremaining: 2.09s\n",
      "548:\tlearn: 58.9344061\ttotal: 2.54s\tremaining: 2.09s\n",
      "549:\tlearn: 58.9162218\ttotal: 2.54s\tremaining: 2.08s\n",
      "550:\tlearn: 58.9003565\ttotal: 2.55s\tremaining: 2.08s\n",
      "551:\tlearn: 58.8461962\ttotal: 2.55s\tremaining: 2.07s\n",
      "552:\tlearn: 58.8390427\ttotal: 2.55s\tremaining: 2.06s\n",
      "553:\tlearn: 58.8378919\ttotal: 2.56s\tremaining: 2.06s\n",
      "554:\tlearn: 58.8327212\ttotal: 2.56s\tremaining: 2.05s\n",
      "555:\tlearn: 58.8253185\ttotal: 2.57s\tremaining: 2.05s\n",
      "556:\tlearn: 58.8108415\ttotal: 2.57s\tremaining: 2.04s\n",
      "557:\tlearn: 58.8061345\ttotal: 2.57s\tremaining: 2.04s\n",
      "558:\tlearn: 58.8020681\ttotal: 2.58s\tremaining: 2.04s\n",
      "559:\tlearn: 58.8005087\ttotal: 2.59s\tremaining: 2.04s\n",
      "560:\tlearn: 58.7908975\ttotal: 2.6s\tremaining: 2.03s\n",
      "561:\tlearn: 58.7879399\ttotal: 2.6s\tremaining: 2.02s\n",
      "562:\tlearn: 58.7844821\ttotal: 2.6s\tremaining: 2.02s\n",
      "563:\tlearn: 58.7747817\ttotal: 2.61s\tremaining: 2.02s\n",
      "564:\tlearn: 58.7737506\ttotal: 2.61s\tremaining: 2.01s\n",
      "565:\tlearn: 58.7694775\ttotal: 2.62s\tremaining: 2.01s\n",
      "566:\tlearn: 58.7640419\ttotal: 2.62s\tremaining: 2s\n",
      "567:\tlearn: 58.7589299\ttotal: 2.63s\tremaining: 2s\n",
      "568:\tlearn: 58.7539399\ttotal: 2.63s\tremaining: 2s\n",
      "569:\tlearn: 58.7464259\ttotal: 2.64s\tremaining: 1.99s\n",
      "570:\tlearn: 58.7311472\ttotal: 2.64s\tremaining: 1.99s\n",
      "571:\tlearn: 58.7299443\ttotal: 2.65s\tremaining: 1.98s\n",
      "572:\tlearn: 58.7244608\ttotal: 2.65s\tremaining: 1.98s\n",
      "573:\tlearn: 58.7235344\ttotal: 2.66s\tremaining: 1.97s\n",
      "574:\tlearn: 58.7150880\ttotal: 2.66s\tremaining: 1.97s\n",
      "575:\tlearn: 58.7146002\ttotal: 2.67s\tremaining: 1.96s\n",
      "576:\tlearn: 58.7140575\ttotal: 2.67s\tremaining: 1.96s\n",
      "577:\tlearn: 58.7107993\ttotal: 2.68s\tremaining: 1.96s\n",
      "578:\tlearn: 58.7082257\ttotal: 2.68s\tremaining: 1.95s\n",
      "579:\tlearn: 58.6972044\ttotal: 2.69s\tremaining: 1.95s\n",
      "580:\tlearn: 58.6935836\ttotal: 2.69s\tremaining: 1.94s\n",
      "581:\tlearn: 58.6874893\ttotal: 2.7s\tremaining: 1.94s\n",
      "582:\tlearn: 58.6862215\ttotal: 2.7s\tremaining: 1.93s\n",
      "583:\tlearn: 58.6688811\ttotal: 2.71s\tremaining: 1.93s\n",
      "584:\tlearn: 58.6633409\ttotal: 2.71s\tremaining: 1.93s\n",
      "585:\tlearn: 58.6618356\ttotal: 2.72s\tremaining: 1.92s\n",
      "586:\tlearn: 58.6521790\ttotal: 2.72s\tremaining: 1.92s\n",
      "587:\tlearn: 58.6457473\ttotal: 2.73s\tremaining: 1.91s\n",
      "588:\tlearn: 58.6392007\ttotal: 2.73s\tremaining: 1.91s\n",
      "589:\tlearn: 58.6377555\ttotal: 2.74s\tremaining: 1.91s\n",
      "590:\tlearn: 58.6356161\ttotal: 2.75s\tremaining: 1.9s\n",
      "591:\tlearn: 58.6156194\ttotal: 2.76s\tremaining: 1.9s\n",
      "592:\tlearn: 58.6117880\ttotal: 2.77s\tremaining: 1.9s\n",
      "593:\tlearn: 58.6083027\ttotal: 2.78s\tremaining: 1.9s\n",
      "594:\tlearn: 58.6035917\ttotal: 2.79s\tremaining: 1.9s\n",
      "595:\tlearn: 58.6015036\ttotal: 2.79s\tremaining: 1.89s\n",
      "596:\tlearn: 58.5949798\ttotal: 2.8s\tremaining: 1.89s\n",
      "597:\tlearn: 58.5856315\ttotal: 2.8s\tremaining: 1.88s\n",
      "598:\tlearn: 58.5790701\ttotal: 2.81s\tremaining: 1.88s\n",
      "599:\tlearn: 58.5709719\ttotal: 2.81s\tremaining: 1.87s\n",
      "600:\tlearn: 58.5602476\ttotal: 2.81s\tremaining: 1.87s\n",
      "601:\tlearn: 58.5487854\ttotal: 2.82s\tremaining: 1.86s\n",
      "602:\tlearn: 58.5457172\ttotal: 2.83s\tremaining: 1.86s\n",
      "603:\tlearn: 58.5438714\ttotal: 2.83s\tremaining: 1.86s\n",
      "604:\tlearn: 58.5406165\ttotal: 2.84s\tremaining: 1.85s\n",
      "605:\tlearn: 58.5242928\ttotal: 2.84s\tremaining: 1.85s\n",
      "606:\tlearn: 58.5220974\ttotal: 2.85s\tremaining: 1.84s\n",
      "607:\tlearn: 58.5138201\ttotal: 2.85s\tremaining: 1.84s\n",
      "608:\tlearn: 58.5124655\ttotal: 2.86s\tremaining: 1.83s\n",
      "609:\tlearn: 58.4981186\ttotal: 2.86s\tremaining: 1.83s\n",
      "610:\tlearn: 58.4904539\ttotal: 2.87s\tremaining: 1.83s\n",
      "611:\tlearn: 58.4855831\ttotal: 2.87s\tremaining: 1.82s\n",
      "612:\tlearn: 58.4797697\ttotal: 2.88s\tremaining: 1.82s\n",
      "613:\tlearn: 58.4705777\ttotal: 2.88s\tremaining: 1.81s\n",
      "614:\tlearn: 58.4649983\ttotal: 2.89s\tremaining: 1.81s\n",
      "615:\tlearn: 58.4533881\ttotal: 2.9s\tremaining: 1.81s\n",
      "616:\tlearn: 58.4517351\ttotal: 2.9s\tremaining: 1.8s\n",
      "617:\tlearn: 58.4484556\ttotal: 2.91s\tremaining: 1.8s\n",
      "618:\tlearn: 58.4467660\ttotal: 2.92s\tremaining: 1.79s\n",
      "619:\tlearn: 58.4435060\ttotal: 2.92s\tremaining: 1.79s\n",
      "620:\tlearn: 58.4359519\ttotal: 2.93s\tremaining: 1.79s\n",
      "621:\tlearn: 58.4347073\ttotal: 2.93s\tremaining: 1.78s\n",
      "622:\tlearn: 58.4331991\ttotal: 2.94s\tremaining: 1.78s\n",
      "623:\tlearn: 58.4318817\ttotal: 2.95s\tremaining: 1.77s\n",
      "624:\tlearn: 58.4280774\ttotal: 2.95s\tremaining: 1.77s\n",
      "625:\tlearn: 58.4245985\ttotal: 2.96s\tremaining: 1.77s\n",
      "626:\tlearn: 58.4201294\ttotal: 2.97s\tremaining: 1.76s\n",
      "627:\tlearn: 58.3654465\ttotal: 2.97s\tremaining: 1.76s\n",
      "628:\tlearn: 58.3644792\ttotal: 2.98s\tremaining: 1.76s\n",
      "629:\tlearn: 58.3555160\ttotal: 2.99s\tremaining: 1.75s\n",
      "630:\tlearn: 58.3543986\ttotal: 2.99s\tremaining: 1.75s\n",
      "631:\tlearn: 58.3490746\ttotal: 3s\tremaining: 1.75s\n",
      "632:\tlearn: 58.3437893\ttotal: 3s\tremaining: 1.74s\n",
      "633:\tlearn: 58.3393625\ttotal: 3.01s\tremaining: 1.74s\n",
      "634:\tlearn: 58.3350661\ttotal: 3.02s\tremaining: 1.73s\n",
      "635:\tlearn: 58.3321152\ttotal: 3.02s\tremaining: 1.73s\n",
      "636:\tlearn: 58.3292856\ttotal: 3.03s\tremaining: 1.73s\n",
      "637:\tlearn: 58.3256617\ttotal: 3.03s\tremaining: 1.72s\n",
      "638:\tlearn: 58.3241441\ttotal: 3.04s\tremaining: 1.72s\n",
      "639:\tlearn: 58.3188529\ttotal: 3.04s\tremaining: 1.71s\n",
      "640:\tlearn: 58.2926965\ttotal: 3.05s\tremaining: 1.71s\n",
      "641:\tlearn: 58.2905613\ttotal: 3.06s\tremaining: 1.7s\n",
      "642:\tlearn: 58.2883917\ttotal: 3.06s\tremaining: 1.7s\n",
      "643:\tlearn: 58.2819306\ttotal: 3.07s\tremaining: 1.7s\n",
      "644:\tlearn: 58.2807424\ttotal: 3.08s\tremaining: 1.69s\n",
      "645:\tlearn: 58.2792024\ttotal: 3.08s\tremaining: 1.69s\n",
      "646:\tlearn: 58.2672222\ttotal: 3.09s\tremaining: 1.68s\n",
      "647:\tlearn: 58.2555676\ttotal: 3.09s\tremaining: 1.68s\n",
      "648:\tlearn: 58.2466908\ttotal: 3.1s\tremaining: 1.68s\n",
      "649:\tlearn: 58.2427716\ttotal: 3.1s\tremaining: 1.67s\n",
      "650:\tlearn: 58.1915306\ttotal: 3.11s\tremaining: 1.67s\n",
      "651:\tlearn: 58.1855000\ttotal: 3.12s\tremaining: 1.66s\n",
      "652:\tlearn: 58.1804416\ttotal: 3.12s\tremaining: 1.66s\n",
      "653:\tlearn: 58.1766831\ttotal: 3.13s\tremaining: 1.65s\n",
      "654:\tlearn: 58.1569280\ttotal: 3.13s\tremaining: 1.65s\n",
      "655:\tlearn: 58.1433948\ttotal: 3.14s\tremaining: 1.65s\n",
      "656:\tlearn: 58.1321783\ttotal: 3.15s\tremaining: 1.64s\n",
      "657:\tlearn: 58.1276758\ttotal: 3.15s\tremaining: 1.64s\n",
      "658:\tlearn: 58.1224093\ttotal: 3.16s\tremaining: 1.63s\n",
      "659:\tlearn: 58.1102165\ttotal: 3.16s\tremaining: 1.63s\n",
      "660:\tlearn: 58.1090874\ttotal: 3.17s\tremaining: 1.62s\n",
      "661:\tlearn: 58.1067220\ttotal: 3.17s\tremaining: 1.62s\n",
      "662:\tlearn: 58.0880487\ttotal: 3.18s\tremaining: 1.62s\n",
      "663:\tlearn: 58.0868316\ttotal: 3.19s\tremaining: 1.61s\n",
      "664:\tlearn: 58.0841931\ttotal: 3.19s\tremaining: 1.61s\n",
      "665:\tlearn: 58.0818742\ttotal: 3.21s\tremaining: 1.61s\n",
      "666:\tlearn: 58.0750561\ttotal: 3.21s\tremaining: 1.6s\n",
      "667:\tlearn: 58.0685663\ttotal: 3.22s\tremaining: 1.6s\n",
      "668:\tlearn: 58.0642130\ttotal: 3.22s\tremaining: 1.59s\n",
      "669:\tlearn: 58.0597370\ttotal: 3.23s\tremaining: 1.59s\n",
      "670:\tlearn: 58.0590433\ttotal: 3.23s\tremaining: 1.58s\n",
      "671:\tlearn: 58.0128906\ttotal: 3.24s\tremaining: 1.58s\n",
      "672:\tlearn: 58.0120885\ttotal: 3.24s\tremaining: 1.57s\n",
      "673:\tlearn: 58.0087612\ttotal: 3.25s\tremaining: 1.57s\n",
      "674:\tlearn: 57.9903292\ttotal: 3.25s\tremaining: 1.56s\n",
      "675:\tlearn: 57.9807689\ttotal: 3.25s\tremaining: 1.56s\n",
      "676:\tlearn: 57.9458247\ttotal: 3.26s\tremaining: 1.55s\n",
      "677:\tlearn: 57.9395759\ttotal: 3.26s\tremaining: 1.55s\n",
      "678:\tlearn: 57.9346687\ttotal: 3.26s\tremaining: 1.54s\n",
      "679:\tlearn: 57.9322361\ttotal: 3.27s\tremaining: 1.54s\n",
      "680:\tlearn: 57.9251484\ttotal: 3.27s\tremaining: 1.53s\n",
      "681:\tlearn: 57.9189823\ttotal: 3.27s\tremaining: 1.53s\n",
      "682:\tlearn: 57.9154788\ttotal: 3.28s\tremaining: 1.52s\n",
      "683:\tlearn: 57.8982668\ttotal: 3.28s\tremaining: 1.52s\n",
      "684:\tlearn: 57.8958121\ttotal: 3.29s\tremaining: 1.51s\n",
      "685:\tlearn: 57.8808146\ttotal: 3.29s\tremaining: 1.51s\n",
      "686:\tlearn: 57.8780617\ttotal: 3.29s\tremaining: 1.5s\n",
      "687:\tlearn: 57.8762082\ttotal: 3.3s\tremaining: 1.5s\n",
      "688:\tlearn: 57.8742030\ttotal: 3.3s\tremaining: 1.49s\n",
      "689:\tlearn: 57.8691079\ttotal: 3.31s\tremaining: 1.49s\n",
      "690:\tlearn: 57.8592649\ttotal: 3.31s\tremaining: 1.48s\n",
      "691:\tlearn: 57.8538313\ttotal: 3.31s\tremaining: 1.48s\n",
      "692:\tlearn: 57.8524415\ttotal: 3.32s\tremaining: 1.47s\n",
      "693:\tlearn: 57.8470043\ttotal: 3.32s\tremaining: 1.47s\n",
      "694:\tlearn: 57.8426747\ttotal: 3.33s\tremaining: 1.46s\n",
      "695:\tlearn: 57.8392550\ttotal: 3.33s\tremaining: 1.46s\n",
      "696:\tlearn: 57.8287248\ttotal: 3.34s\tremaining: 1.45s\n",
      "697:\tlearn: 57.8113015\ttotal: 3.34s\tremaining: 1.45s\n",
      "698:\tlearn: 57.7988613\ttotal: 3.34s\tremaining: 1.44s\n",
      "699:\tlearn: 57.7828608\ttotal: 3.35s\tremaining: 1.44s\n",
      "700:\tlearn: 57.7818538\ttotal: 3.35s\tremaining: 1.43s\n",
      "701:\tlearn: 57.7793366\ttotal: 3.36s\tremaining: 1.43s\n",
      "702:\tlearn: 57.7759388\ttotal: 3.37s\tremaining: 1.42s\n",
      "703:\tlearn: 57.7721021\ttotal: 3.37s\tremaining: 1.42s\n",
      "704:\tlearn: 57.7651280\ttotal: 3.38s\tremaining: 1.41s\n",
      "705:\tlearn: 57.7637645\ttotal: 3.38s\tremaining: 1.41s\n",
      "706:\tlearn: 57.7604370\ttotal: 3.39s\tremaining: 1.4s\n",
      "707:\tlearn: 57.7598230\ttotal: 3.39s\tremaining: 1.4s\n",
      "708:\tlearn: 57.7529324\ttotal: 3.4s\tremaining: 1.4s\n",
      "709:\tlearn: 57.7456200\ttotal: 3.4s\tremaining: 1.39s\n",
      "710:\tlearn: 57.7427769\ttotal: 3.41s\tremaining: 1.39s\n",
      "711:\tlearn: 57.7392773\ttotal: 3.42s\tremaining: 1.38s\n",
      "712:\tlearn: 57.7388924\ttotal: 3.42s\tremaining: 1.38s\n",
      "713:\tlearn: 57.7362566\ttotal: 3.42s\tremaining: 1.37s\n",
      "714:\tlearn: 57.7328486\ttotal: 3.43s\tremaining: 1.37s\n",
      "715:\tlearn: 57.7227501\ttotal: 3.43s\tremaining: 1.36s\n",
      "716:\tlearn: 57.7150707\ttotal: 3.43s\tremaining: 1.35s\n",
      "717:\tlearn: 57.7062056\ttotal: 3.44s\tremaining: 1.35s\n",
      "718:\tlearn: 57.7038926\ttotal: 3.44s\tremaining: 1.34s\n",
      "719:\tlearn: 57.6931202\ttotal: 3.45s\tremaining: 1.34s\n",
      "720:\tlearn: 57.6868628\ttotal: 3.45s\tremaining: 1.33s\n",
      "721:\tlearn: 57.6861473\ttotal: 3.45s\tremaining: 1.33s\n",
      "722:\tlearn: 57.6809852\ttotal: 3.46s\tremaining: 1.32s\n",
      "723:\tlearn: 57.6803093\ttotal: 3.46s\tremaining: 1.32s\n",
      "724:\tlearn: 57.6751167\ttotal: 3.46s\tremaining: 1.31s\n",
      "725:\tlearn: 57.6745839\ttotal: 3.47s\tremaining: 1.31s\n",
      "726:\tlearn: 57.6679874\ttotal: 3.47s\tremaining: 1.3s\n",
      "727:\tlearn: 57.6647238\ttotal: 3.48s\tremaining: 1.3s\n",
      "728:\tlearn: 57.6592328\ttotal: 3.48s\tremaining: 1.29s\n",
      "729:\tlearn: 57.6472946\ttotal: 3.48s\tremaining: 1.29s\n",
      "730:\tlearn: 57.6303752\ttotal: 3.49s\tremaining: 1.28s\n",
      "731:\tlearn: 57.6252237\ttotal: 3.49s\tremaining: 1.28s\n",
      "732:\tlearn: 57.6222462\ttotal: 3.5s\tremaining: 1.27s\n",
      "733:\tlearn: 57.6096574\ttotal: 3.5s\tremaining: 1.27s\n",
      "734:\tlearn: 57.6082646\ttotal: 3.5s\tremaining: 1.26s\n",
      "735:\tlearn: 57.6080789\ttotal: 3.51s\tremaining: 1.26s\n",
      "736:\tlearn: 57.5954338\ttotal: 3.51s\tremaining: 1.25s\n",
      "737:\tlearn: 57.5914587\ttotal: 3.52s\tremaining: 1.25s\n",
      "738:\tlearn: 57.5834815\ttotal: 3.52s\tremaining: 1.24s\n",
      "739:\tlearn: 57.5781163\ttotal: 3.52s\tremaining: 1.24s\n",
      "740:\tlearn: 57.5721659\ttotal: 3.53s\tremaining: 1.23s\n",
      "741:\tlearn: 57.5702556\ttotal: 3.53s\tremaining: 1.23s\n",
      "742:\tlearn: 57.5691407\ttotal: 3.54s\tremaining: 1.22s\n",
      "743:\tlearn: 57.5658761\ttotal: 3.54s\tremaining: 1.22s\n",
      "744:\tlearn: 57.5638157\ttotal: 3.54s\tremaining: 1.21s\n",
      "745:\tlearn: 57.5614527\ttotal: 3.55s\tremaining: 1.21s\n",
      "746:\tlearn: 57.5610883\ttotal: 3.56s\tremaining: 1.2s\n",
      "747:\tlearn: 57.5597917\ttotal: 3.56s\tremaining: 1.2s\n",
      "748:\tlearn: 57.5562878\ttotal: 3.57s\tremaining: 1.2s\n",
      "749:\tlearn: 57.5435344\ttotal: 3.57s\tremaining: 1.19s\n",
      "750:\tlearn: 57.5390023\ttotal: 3.58s\tremaining: 1.19s\n",
      "751:\tlearn: 57.5380622\ttotal: 3.58s\tremaining: 1.18s\n",
      "752:\tlearn: 57.5373234\ttotal: 3.58s\tremaining: 1.18s\n",
      "753:\tlearn: 57.5314871\ttotal: 3.59s\tremaining: 1.17s\n",
      "754:\tlearn: 57.5201830\ttotal: 3.59s\tremaining: 1.17s\n",
      "755:\tlearn: 57.5177033\ttotal: 3.6s\tremaining: 1.16s\n",
      "756:\tlearn: 57.5112395\ttotal: 3.6s\tremaining: 1.16s\n",
      "757:\tlearn: 57.5100774\ttotal: 3.6s\tremaining: 1.15s\n",
      "758:\tlearn: 57.5069627\ttotal: 3.61s\tremaining: 1.15s\n",
      "759:\tlearn: 57.5020101\ttotal: 3.61s\tremaining: 1.14s\n",
      "760:\tlearn: 57.5000956\ttotal: 3.61s\tremaining: 1.14s\n",
      "761:\tlearn: 57.4994449\ttotal: 3.62s\tremaining: 1.13s\n",
      "762:\tlearn: 57.4956759\ttotal: 3.62s\tremaining: 1.13s\n",
      "763:\tlearn: 57.4929093\ttotal: 3.63s\tremaining: 1.12s\n",
      "764:\tlearn: 57.4843986\ttotal: 3.63s\tremaining: 1.11s\n",
      "765:\tlearn: 57.4744885\ttotal: 3.63s\tremaining: 1.11s\n",
      "766:\tlearn: 57.4732155\ttotal: 3.64s\tremaining: 1.1s\n",
      "767:\tlearn: 57.4618418\ttotal: 3.64s\tremaining: 1.1s\n",
      "768:\tlearn: 57.4593751\ttotal: 3.65s\tremaining: 1.09s\n",
      "769:\tlearn: 57.4461028\ttotal: 3.65s\tremaining: 1.09s\n",
      "770:\tlearn: 57.4431084\ttotal: 3.65s\tremaining: 1.08s\n",
      "771:\tlearn: 57.4418994\ttotal: 3.66s\tremaining: 1.08s\n",
      "772:\tlearn: 57.4328600\ttotal: 3.66s\tremaining: 1.07s\n",
      "773:\tlearn: 57.4285520\ttotal: 3.66s\tremaining: 1.07s\n",
      "774:\tlearn: 57.4214696\ttotal: 3.67s\tremaining: 1.06s\n",
      "775:\tlearn: 57.4106505\ttotal: 3.67s\tremaining: 1.06s\n",
      "776:\tlearn: 57.4094785\ttotal: 3.67s\tremaining: 1.05s\n",
      "777:\tlearn: 57.4049966\ttotal: 3.68s\tremaining: 1.05s\n",
      "778:\tlearn: 57.3981671\ttotal: 3.68s\tremaining: 1.04s\n",
      "779:\tlearn: 57.3845441\ttotal: 3.69s\tremaining: 1.04s\n",
      "780:\tlearn: 57.3736365\ttotal: 3.69s\tremaining: 1.03s\n",
      "781:\tlearn: 57.3690236\ttotal: 3.69s\tremaining: 1.03s\n",
      "782:\tlearn: 57.3670987\ttotal: 3.7s\tremaining: 1.02s\n",
      "783:\tlearn: 57.3635626\ttotal: 3.7s\tremaining: 1.02s\n",
      "784:\tlearn: 57.3620616\ttotal: 3.71s\tremaining: 1.01s\n",
      "785:\tlearn: 57.3515372\ttotal: 3.71s\tremaining: 1.01s\n",
      "786:\tlearn: 57.3494805\ttotal: 3.71s\tremaining: 1s\n",
      "787:\tlearn: 57.3428932\ttotal: 3.72s\tremaining: 1000ms\n",
      "788:\tlearn: 57.3365119\ttotal: 3.72s\tremaining: 995ms\n",
      "789:\tlearn: 57.3215608\ttotal: 3.73s\tremaining: 990ms\n",
      "790:\tlearn: 57.3196339\ttotal: 3.73s\tremaining: 986ms\n",
      "791:\tlearn: 57.3186042\ttotal: 3.73s\tremaining: 981ms\n",
      "792:\tlearn: 57.2744125\ttotal: 3.74s\tremaining: 976ms\n",
      "793:\tlearn: 57.2694942\ttotal: 3.74s\tremaining: 971ms\n",
      "794:\tlearn: 57.2659355\ttotal: 3.75s\tremaining: 966ms\n",
      "795:\tlearn: 57.2486869\ttotal: 3.75s\tremaining: 962ms\n",
      "796:\tlearn: 57.2455174\ttotal: 3.76s\tremaining: 957ms\n",
      "797:\tlearn: 57.2445810\ttotal: 3.76s\tremaining: 953ms\n",
      "798:\tlearn: 57.2353690\ttotal: 3.77s\tremaining: 948ms\n",
      "799:\tlearn: 57.2191517\ttotal: 3.77s\tremaining: 943ms\n",
      "800:\tlearn: 57.2183477\ttotal: 3.78s\tremaining: 938ms\n",
      "801:\tlearn: 57.2146340\ttotal: 3.78s\tremaining: 933ms\n",
      "802:\tlearn: 57.2124449\ttotal: 3.78s\tremaining: 928ms\n",
      "803:\tlearn: 57.2063903\ttotal: 3.79s\tremaining: 923ms\n",
      "804:\tlearn: 57.2042390\ttotal: 3.79s\tremaining: 918ms\n",
      "805:\tlearn: 57.1864386\ttotal: 3.79s\tremaining: 914ms\n",
      "806:\tlearn: 57.1822846\ttotal: 3.8s\tremaining: 908ms\n",
      "807:\tlearn: 57.1771122\ttotal: 3.8s\tremaining: 903ms\n",
      "808:\tlearn: 57.1598357\ttotal: 3.81s\tremaining: 899ms\n",
      "809:\tlearn: 57.1475663\ttotal: 3.81s\tremaining: 894ms\n",
      "810:\tlearn: 57.1386150\ttotal: 3.81s\tremaining: 889ms\n",
      "811:\tlearn: 57.1117809\ttotal: 3.82s\tremaining: 884ms\n",
      "812:\tlearn: 57.1092507\ttotal: 3.82s\tremaining: 879ms\n",
      "813:\tlearn: 57.1030165\ttotal: 3.82s\tremaining: 874ms\n",
      "814:\tlearn: 57.1001594\ttotal: 3.83s\tremaining: 869ms\n",
      "815:\tlearn: 57.0979755\ttotal: 3.83s\tremaining: 864ms\n",
      "816:\tlearn: 57.0952363\ttotal: 3.84s\tremaining: 860ms\n",
      "817:\tlearn: 57.0906668\ttotal: 3.84s\tremaining: 855ms\n",
      "818:\tlearn: 57.0892429\ttotal: 3.85s\tremaining: 850ms\n",
      "819:\tlearn: 57.0805435\ttotal: 3.85s\tremaining: 846ms\n",
      "820:\tlearn: 57.0798607\ttotal: 3.85s\tremaining: 841ms\n",
      "821:\tlearn: 57.0785147\ttotal: 3.86s\tremaining: 836ms\n",
      "822:\tlearn: 57.0678060\ttotal: 3.86s\tremaining: 831ms\n",
      "823:\tlearn: 57.0672758\ttotal: 3.87s\tremaining: 826ms\n",
      "824:\tlearn: 57.0662803\ttotal: 3.87s\tremaining: 821ms\n",
      "825:\tlearn: 57.0637025\ttotal: 3.88s\tremaining: 816ms\n",
      "826:\tlearn: 57.0630203\ttotal: 3.88s\tremaining: 812ms\n",
      "827:\tlearn: 57.0605978\ttotal: 3.89s\tremaining: 808ms\n",
      "828:\tlearn: 57.0595747\ttotal: 3.9s\tremaining: 804ms\n",
      "829:\tlearn: 57.0475751\ttotal: 3.9s\tremaining: 799ms\n",
      "830:\tlearn: 57.0459169\ttotal: 3.91s\tremaining: 795ms\n",
      "831:\tlearn: 57.0448055\ttotal: 3.92s\tremaining: 791ms\n",
      "832:\tlearn: 57.0446117\ttotal: 3.92s\tremaining: 786ms\n",
      "833:\tlearn: 57.0438898\ttotal: 3.92s\tremaining: 781ms\n",
      "834:\tlearn: 57.0420959\ttotal: 3.93s\tremaining: 776ms\n",
      "835:\tlearn: 57.0407123\ttotal: 3.93s\tremaining: 771ms\n",
      "836:\tlearn: 57.0384258\ttotal: 3.93s\tremaining: 766ms\n",
      "837:\tlearn: 57.0327056\ttotal: 3.94s\tremaining: 761ms\n",
      "838:\tlearn: 57.0318428\ttotal: 3.94s\tremaining: 757ms\n",
      "839:\tlearn: 57.0303777\ttotal: 3.95s\tremaining: 752ms\n",
      "840:\tlearn: 57.0237093\ttotal: 3.96s\tremaining: 748ms\n",
      "841:\tlearn: 57.0222315\ttotal: 3.96s\tremaining: 743ms\n",
      "842:\tlearn: 57.0199002\ttotal: 3.96s\tremaining: 738ms\n",
      "843:\tlearn: 57.0102437\ttotal: 3.97s\tremaining: 733ms\n",
      "844:\tlearn: 57.0051621\ttotal: 3.97s\tremaining: 728ms\n",
      "845:\tlearn: 57.0041523\ttotal: 3.97s\tremaining: 723ms\n",
      "846:\tlearn: 56.9928983\ttotal: 3.98s\tremaining: 719ms\n",
      "847:\tlearn: 56.9914207\ttotal: 3.98s\tremaining: 714ms\n",
      "848:\tlearn: 56.9889498\ttotal: 3.98s\tremaining: 709ms\n",
      "849:\tlearn: 56.9867043\ttotal: 3.99s\tremaining: 704ms\n",
      "850:\tlearn: 56.9841607\ttotal: 3.99s\tremaining: 699ms\n",
      "851:\tlearn: 56.9800384\ttotal: 4s\tremaining: 694ms\n",
      "852:\tlearn: 56.9386448\ttotal: 4s\tremaining: 690ms\n",
      "853:\tlearn: 56.9252320\ttotal: 4s\tremaining: 685ms\n",
      "854:\tlearn: 56.9209917\ttotal: 4.01s\tremaining: 680ms\n",
      "855:\tlearn: 56.9185027\ttotal: 4.01s\tremaining: 675ms\n",
      "856:\tlearn: 56.9176860\ttotal: 4.02s\tremaining: 671ms\n",
      "857:\tlearn: 56.9161150\ttotal: 4.02s\tremaining: 666ms\n",
      "858:\tlearn: 56.9107993\ttotal: 4.03s\tremaining: 661ms\n",
      "859:\tlearn: 56.9096966\ttotal: 4.03s\tremaining: 656ms\n",
      "860:\tlearn: 56.9016109\ttotal: 4.03s\tremaining: 651ms\n",
      "861:\tlearn: 56.8989547\ttotal: 4.04s\tremaining: 646ms\n",
      "862:\tlearn: 56.8924705\ttotal: 4.04s\tremaining: 641ms\n",
      "863:\tlearn: 56.8849194\ttotal: 4.04s\tremaining: 637ms\n",
      "864:\tlearn: 56.8743289\ttotal: 4.05s\tremaining: 632ms\n",
      "865:\tlearn: 56.8659712\ttotal: 4.05s\tremaining: 627ms\n",
      "866:\tlearn: 56.8649993\ttotal: 4.06s\tremaining: 622ms\n",
      "867:\tlearn: 56.8604716\ttotal: 4.06s\tremaining: 617ms\n",
      "868:\tlearn: 56.8582707\ttotal: 4.06s\tremaining: 613ms\n",
      "869:\tlearn: 56.8480068\ttotal: 4.07s\tremaining: 608ms\n",
      "870:\tlearn: 56.8413912\ttotal: 4.07s\tremaining: 603ms\n",
      "871:\tlearn: 56.8401854\ttotal: 4.07s\tremaining: 598ms\n",
      "872:\tlearn: 56.8393450\ttotal: 4.08s\tremaining: 593ms\n",
      "873:\tlearn: 56.8363839\ttotal: 4.08s\tremaining: 589ms\n",
      "874:\tlearn: 56.8312738\ttotal: 4.09s\tremaining: 584ms\n",
      "875:\tlearn: 56.8304772\ttotal: 4.09s\tremaining: 579ms\n",
      "876:\tlearn: 56.8260514\ttotal: 4.09s\tremaining: 574ms\n",
      "877:\tlearn: 56.8226941\ttotal: 4.1s\tremaining: 569ms\n",
      "878:\tlearn: 56.8175717\ttotal: 4.1s\tremaining: 565ms\n",
      "879:\tlearn: 56.8159709\ttotal: 4.11s\tremaining: 560ms\n",
      "880:\tlearn: 56.8129229\ttotal: 4.11s\tremaining: 555ms\n",
      "881:\tlearn: 56.8128619\ttotal: 4.11s\tremaining: 550ms\n",
      "882:\tlearn: 56.8077077\ttotal: 4.12s\tremaining: 546ms\n",
      "883:\tlearn: 56.8068872\ttotal: 4.12s\tremaining: 541ms\n",
      "884:\tlearn: 56.8030173\ttotal: 4.13s\tremaining: 536ms\n",
      "885:\tlearn: 56.8014158\ttotal: 4.13s\tremaining: 531ms\n",
      "886:\tlearn: 56.8011266\ttotal: 4.13s\tremaining: 527ms\n",
      "887:\tlearn: 56.7924774\ttotal: 4.14s\tremaining: 522ms\n",
      "888:\tlearn: 56.7901876\ttotal: 4.15s\tremaining: 518ms\n",
      "889:\tlearn: 56.7894386\ttotal: 4.15s\tremaining: 513ms\n",
      "890:\tlearn: 56.7876111\ttotal: 4.16s\tremaining: 509ms\n",
      "891:\tlearn: 56.7778478\ttotal: 4.16s\tremaining: 504ms\n",
      "892:\tlearn: 56.7728858\ttotal: 4.17s\tremaining: 499ms\n",
      "893:\tlearn: 56.7597660\ttotal: 4.17s\tremaining: 495ms\n",
      "894:\tlearn: 56.7518043\ttotal: 4.17s\tremaining: 490ms\n",
      "895:\tlearn: 56.7492286\ttotal: 4.18s\tremaining: 485ms\n",
      "896:\tlearn: 56.7323705\ttotal: 4.18s\tremaining: 480ms\n",
      "897:\tlearn: 56.7299893\ttotal: 4.19s\tremaining: 476ms\n",
      "898:\tlearn: 56.7261030\ttotal: 4.19s\tremaining: 471ms\n",
      "899:\tlearn: 56.7132455\ttotal: 4.2s\tremaining: 466ms\n",
      "900:\tlearn: 56.7113962\ttotal: 4.2s\tremaining: 461ms\n",
      "901:\tlearn: 56.7099478\ttotal: 4.2s\tremaining: 457ms\n",
      "902:\tlearn: 56.7069153\ttotal: 4.21s\tremaining: 452ms\n",
      "903:\tlearn: 56.7053959\ttotal: 4.21s\tremaining: 447ms\n",
      "904:\tlearn: 56.7040665\ttotal: 4.21s\tremaining: 442ms\n",
      "905:\tlearn: 56.7032371\ttotal: 4.22s\tremaining: 438ms\n",
      "906:\tlearn: 56.6937122\ttotal: 4.22s\tremaining: 433ms\n",
      "907:\tlearn: 56.6843948\ttotal: 4.23s\tremaining: 428ms\n",
      "908:\tlearn: 56.6783920\ttotal: 4.23s\tremaining: 424ms\n",
      "909:\tlearn: 56.6723696\ttotal: 4.24s\tremaining: 419ms\n",
      "910:\tlearn: 56.6702529\ttotal: 4.24s\tremaining: 414ms\n",
      "911:\tlearn: 56.6681573\ttotal: 4.24s\tremaining: 409ms\n",
      "912:\tlearn: 56.6595766\ttotal: 4.25s\tremaining: 405ms\n",
      "913:\tlearn: 56.6569768\ttotal: 4.25s\tremaining: 400ms\n",
      "914:\tlearn: 56.6384021\ttotal: 4.25s\tremaining: 395ms\n",
      "915:\tlearn: 56.6319359\ttotal: 4.26s\tremaining: 390ms\n",
      "916:\tlearn: 56.6277745\ttotal: 4.26s\tremaining: 386ms\n",
      "917:\tlearn: 56.6224419\ttotal: 4.26s\tremaining: 381ms\n",
      "918:\tlearn: 56.6210504\ttotal: 4.27s\tremaining: 376ms\n",
      "919:\tlearn: 56.6189680\ttotal: 4.27s\tremaining: 372ms\n",
      "920:\tlearn: 56.6153193\ttotal: 4.28s\tremaining: 367ms\n",
      "921:\tlearn: 56.6032459\ttotal: 4.28s\tremaining: 362ms\n",
      "922:\tlearn: 56.5993561\ttotal: 4.28s\tremaining: 357ms\n",
      "923:\tlearn: 56.5935927\ttotal: 4.29s\tremaining: 353ms\n",
      "924:\tlearn: 56.5913410\ttotal: 4.29s\tremaining: 348ms\n",
      "925:\tlearn: 56.5906192\ttotal: 4.29s\tremaining: 343ms\n",
      "926:\tlearn: 56.5874002\ttotal: 4.3s\tremaining: 339ms\n",
      "927:\tlearn: 56.5828442\ttotal: 4.3s\tremaining: 334ms\n",
      "928:\tlearn: 56.5778668\ttotal: 4.31s\tremaining: 329ms\n",
      "929:\tlearn: 56.5763666\ttotal: 4.31s\tremaining: 324ms\n",
      "930:\tlearn: 56.5737003\ttotal: 4.31s\tremaining: 320ms\n",
      "931:\tlearn: 56.5679410\ttotal: 4.32s\tremaining: 315ms\n",
      "932:\tlearn: 56.5657580\ttotal: 4.32s\tremaining: 310ms\n",
      "933:\tlearn: 56.5643367\ttotal: 4.32s\tremaining: 306ms\n",
      "934:\tlearn: 56.5633735\ttotal: 4.33s\tremaining: 301ms\n",
      "935:\tlearn: 56.5618915\ttotal: 4.33s\tremaining: 296ms\n",
      "936:\tlearn: 56.5565601\ttotal: 4.34s\tremaining: 292ms\n",
      "937:\tlearn: 56.5548117\ttotal: 4.35s\tremaining: 287ms\n",
      "938:\tlearn: 56.5514595\ttotal: 4.35s\tremaining: 283ms\n",
      "939:\tlearn: 56.5470164\ttotal: 4.36s\tremaining: 278ms\n",
      "940:\tlearn: 56.5466065\ttotal: 4.36s\tremaining: 273ms\n",
      "941:\tlearn: 56.5387300\ttotal: 4.36s\tremaining: 269ms\n",
      "942:\tlearn: 56.5369766\ttotal: 4.37s\tremaining: 264ms\n",
      "943:\tlearn: 56.5346605\ttotal: 4.37s\tremaining: 259ms\n",
      "944:\tlearn: 56.5244593\ttotal: 4.37s\tremaining: 255ms\n",
      "945:\tlearn: 56.5240484\ttotal: 4.38s\tremaining: 250ms\n",
      "946:\tlearn: 56.5113573\ttotal: 4.38s\tremaining: 245ms\n",
      "947:\tlearn: 56.5067292\ttotal: 4.38s\tremaining: 240ms\n",
      "948:\tlearn: 56.5048511\ttotal: 4.39s\tremaining: 236ms\n",
      "949:\tlearn: 56.4664531\ttotal: 4.39s\tremaining: 231ms\n",
      "950:\tlearn: 56.4627575\ttotal: 4.39s\tremaining: 226ms\n",
      "951:\tlearn: 56.4603090\ttotal: 4.4s\tremaining: 222ms\n",
      "952:\tlearn: 56.4479980\ttotal: 4.4s\tremaining: 217ms\n",
      "953:\tlearn: 56.4421519\ttotal: 4.41s\tremaining: 212ms\n",
      "954:\tlearn: 56.4410594\ttotal: 4.41s\tremaining: 208ms\n",
      "955:\tlearn: 56.4389900\ttotal: 4.41s\tremaining: 203ms\n",
      "956:\tlearn: 56.4288536\ttotal: 4.42s\tremaining: 198ms\n",
      "957:\tlearn: 56.4272659\ttotal: 4.42s\tremaining: 194ms\n",
      "958:\tlearn: 56.4027274\ttotal: 4.42s\tremaining: 189ms\n",
      "959:\tlearn: 56.4007711\ttotal: 4.43s\tremaining: 185ms\n",
      "960:\tlearn: 56.3972152\ttotal: 4.43s\tremaining: 180ms\n",
      "961:\tlearn: 56.3963803\ttotal: 4.44s\tremaining: 176ms\n",
      "962:\tlearn: 56.3920976\ttotal: 4.45s\tremaining: 171ms\n",
      "963:\tlearn: 56.3914847\ttotal: 4.46s\tremaining: 167ms\n",
      "964:\tlearn: 56.3897914\ttotal: 4.46s\tremaining: 162ms\n",
      "965:\tlearn: 56.3867572\ttotal: 4.47s\tremaining: 157ms\n",
      "966:\tlearn: 56.3843042\ttotal: 4.47s\tremaining: 153ms\n",
      "967:\tlearn: 56.3823384\ttotal: 4.48s\tremaining: 148ms\n",
      "968:\tlearn: 56.3780734\ttotal: 4.48s\tremaining: 143ms\n",
      "969:\tlearn: 56.3776512\ttotal: 4.49s\tremaining: 139ms\n",
      "970:\tlearn: 56.3440000\ttotal: 4.49s\tremaining: 134ms\n",
      "971:\tlearn: 56.3232480\ttotal: 4.49s\tremaining: 129ms\n",
      "972:\tlearn: 56.3199638\ttotal: 4.5s\tremaining: 125ms\n",
      "973:\tlearn: 56.3198216\ttotal: 4.5s\tremaining: 120ms\n",
      "974:\tlearn: 56.3171840\ttotal: 4.51s\tremaining: 116ms\n",
      "975:\tlearn: 56.3164942\ttotal: 4.51s\tremaining: 111ms\n",
      "976:\tlearn: 56.3119469\ttotal: 4.51s\tremaining: 106ms\n",
      "977:\tlearn: 56.3105698\ttotal: 4.52s\tremaining: 102ms\n",
      "978:\tlearn: 56.3056102\ttotal: 4.52s\tremaining: 97ms\n",
      "979:\tlearn: 56.2973634\ttotal: 4.53s\tremaining: 92.4ms\n",
      "980:\tlearn: 56.2964240\ttotal: 4.53s\tremaining: 87.8ms\n",
      "981:\tlearn: 56.2913034\ttotal: 4.54s\tremaining: 83.2ms\n",
      "982:\tlearn: 56.2887286\ttotal: 4.54s\tremaining: 78.6ms\n",
      "983:\tlearn: 56.2879150\ttotal: 4.55s\tremaining: 73.9ms\n",
      "984:\tlearn: 56.2874113\ttotal: 4.55s\tremaining: 69.3ms\n",
      "985:\tlearn: 56.2848680\ttotal: 4.55s\tremaining: 64.7ms\n",
      "986:\tlearn: 56.2801069\ttotal: 4.56s\tremaining: 60.1ms\n",
      "987:\tlearn: 56.2717889\ttotal: 4.56s\tremaining: 55.4ms\n",
      "988:\tlearn: 56.2705339\ttotal: 4.57s\tremaining: 50.8ms\n",
      "989:\tlearn: 56.2690441\ttotal: 4.57s\tremaining: 46.2ms\n",
      "990:\tlearn: 56.2655170\ttotal: 4.58s\tremaining: 41.6ms\n",
      "991:\tlearn: 56.2629490\ttotal: 4.58s\tremaining: 36.9ms\n",
      "992:\tlearn: 56.2602176\ttotal: 4.58s\tremaining: 32.3ms\n",
      "993:\tlearn: 56.2495087\ttotal: 4.59s\tremaining: 27.7ms\n",
      "994:\tlearn: 56.2411515\ttotal: 4.59s\tremaining: 23.1ms\n",
      "995:\tlearn: 56.2374740\ttotal: 4.6s\tremaining: 18.5ms\n",
      "996:\tlearn: 56.2351080\ttotal: 4.6s\tremaining: 13.8ms\n",
      "997:\tlearn: 56.2350546\ttotal: 4.61s\tremaining: 9.23ms\n",
      "998:\tlearn: 56.2318266\ttotal: 4.61s\tremaining: 4.61ms\n",
      "999:\tlearn: 56.2291184\ttotal: 4.61s\tremaining: 0us\n",
      "52.23\n",
      "38.69\n",
      "56.78\n",
      "74.19\n",
      "41.07\n",
      "+---------------------------+----------+-------+---------+----------+----------+\n",
      "|           Model           | Dataset  |  MAE  |   MSE   | R² score | Variance |\n",
      "+---------------------------+----------+-------+---------+----------+----------+\n",
      "|     CatBoostRegressor     | training | 55.60 | 6356.81 |   0.80   |   3.37   |\n",
      "|       LGBMRegressor       | training | 46.81 | 4197.48 |   0.87   |   8.12   |\n",
      "| GradientBoostingRegressor | training | 58.60 | 6593.21 |   0.79   |   1.82   |\n",
      "|     AdaBoostRegressor     | training | 73.08 | 9057.61 |   0.72   |   1.11   |\n",
      "|   RandomForestRegressor   | training | 50.10 | 5159.19 |   0.84   |   9.03   |\n",
      "+---------------------------+----------+-------+---------+----------+----------+\n",
      "CPU times: user 4min 15s, sys: 3.37 s, total: 4min 19s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model in models:\n",
    "    dataset = 'training'\n",
    "    \n",
    "    # Model training\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make prediction on test and training data set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_res  = model.predict(X_train)\n",
    "\n",
    "    # Evaluate model performance (for shortness of time will only CV MAE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    score = model.score(X_test, y_test)\n",
    "    # Cross-Validated Mean Absolute Deviation regression loss\n",
    "    mae = -np.mean(cross_val_score(model, X_train, y_train, cv=3, n_jobs=-1,\n",
    "                                   scoring=\"neg_mean_absolute_error\"))    \n",
    "    \n",
    "    variance  = abs(mean_absolute_error(y_train, y_res) - mae)\n",
    "    \n",
    "    print(\"%.2f\" % mean_absolute_error(y_train, y_res))\n",
    "\n",
    "    \n",
    "    table.add_row([type(model).__name__, \n",
    "                   dataset,\n",
    "                   format(mae, '.2f'),\n",
    "                   format(mse, '.2f'),   \n",
    "                   format(score, '.2f'),\n",
    "                   format(variance, '.2f')\n",
    "                  ],\n",
    "                 )\n",
    "    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table summary of model's performance across various evaluation metrics typically used in regression problems. For our purposes the most import one being the Mean Absolute Deviation (MAE).\n",
    "\n",
    "```\n",
    "+---------------------------+----------+-------+---------+----------+----------+\n",
    "|           Model           | Dataset  |  MAE  |   MSE   | R² score | Variance |\n",
    "+---------------------------+----------+-------+---------+----------+----------+\n",
    "|     CatBoostRegressor     | training | 55.60 | 6356.81 |   0.80   |   3.37   |\n",
    "|       LGBMRegressor       | training | 46.81 | 4197.48 |   0.87   |   8.12   |\n",
    "| GradientBoostingRegressor | training | 58.60 | 6593.21 |   0.79   |   1.82   |\n",
    "|     AdaBoostRegressor     | training | 73.08 | 9057.61 |   0.72   |   1.11   |\n",
    "|   RandomForestRegressor   | training | 50.10 | 5159.19 |   0.84   |   9.03   |\n",
    "+---------------------------+----------+-------+---------+----------+----------+\n",
    "```\n",
    "\n",
    "\n",
    "From the table above LGBMRegressor performs best with MAE of 46.81, outperforming linear/sgd-base regression algorithms, but with similar performance as RandomForestRegressor if we factor in the spread in variance of 8.12 on the model's prediction. For this reason we will selected the LGBMRegressor algorithms as our choice of model for further tuning using Bayesian Optimization discussed in the model optimization notebook. Training MAE evaluation ranges between 38.69 - 74.19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate model prediction\n",
    "predicted = cross_val_predict(\n",
    "    lgbm.sklearn.LGBMRegressor(boosting_type='gbdt', \n",
    "                               objective='regression',\n",
    "                               min_child_samples=10,  \n",
    "                               max_depth=-1,\n",
    "                               categorical_feature=cat_attr_list,\n",
    "                               nthread=-1,\n",
    "                               random_state=42\n",
    "                              ), \n",
    "    X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200b5150>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysing Residuals in model's predictinos\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(y_train, y_train-predicted)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "ax.set_title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this residual plot we observe a upward linear trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Summary\n",
    "\n",
    "After looking at the performance across all the models, we will decide to select a tree-ensemble based algorithm, in particular the CatBoostRegressor algorith as it has great performance with a mean absoluate deviation of about 31.5 and a standar deviation of less than 4.0. We select this model over LGBMRegressor with a mean absolute devation of 27.98 although it has a better performance it has a larger variance of almost 6.0. Both models perform similarly if we factor in the level of varinace, so we make the conservative choice of going with the one with slightly lower varinace as it stand a better chance to perform better in production making predictions on new unseen data.\n",
    "\n",
    "We can next try some feature engineering in order to possible improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feagure Engineering\n",
    "\n",
    "We try to build new features that we can employ in our predictive modeling step, relating temperature and weather information together and see if generates model performance improvement above baseline (without new features). Feature engineering involves turning available data-features into more useful variables that can help us predict our outcome.\n",
    "\n",
    "- Extracting the week number from the date. The date itself, in the format provided, isn’t something that can be processed in our algorithms. From this date, however, we can extract the week number (for that particular using features based on temparature) and use that variable as a predictor for the usage count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_diff = data.atemp - data.temp\n",
    "ratio_cnt = data.casual / data.registered\n",
    "heat      = data.atemp * data.humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([ratio_cnt, temp_diff, heat,\n",
    "                      data.total_count, data.season, data.year, data.month, data.hour, data.is_holiday,\n",
    "                      data.weekday, data.is_workingday, data.weather_condition, data.windspeed\n",
    "                     ],\n",
    "                     axis=1,\n",
    "                     join='outer',\n",
    "                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio_cnt</th>\n",
       "      <th>temp_diff</th>\n",
       "      <th>heat</th>\n",
       "      <th>total_count</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_workingday</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.233199</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.218160</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.218160</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.215925</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.215925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio_cnt  temp_diff      heat  total_count season year month hour  \\\n",
       "0   0.230769     0.0479  0.233199           16      1    0     1    0   \n",
       "1   0.250000     0.0527  0.218160           40      1    0     1    1   \n",
       "2   0.185185     0.0527  0.218160           32      1    0     1    2   \n",
       "3   0.300000     0.0479  0.215925           13      1    0     1    3   \n",
       "4   0.000000     0.0479  0.215925            1      1    0     1    4   \n",
       "\n",
       "  is_holiday weekday is_workingday weather_condition  windspeed  \n",
       "0          0       6             0                 1        0.0  \n",
       "1          0       6             0                 1        0.0  \n",
       "2          0       6             0                 1        0.0  \n",
       "3          0       6             0                 1        0.0  \n",
       "4          0       6             0                 1        0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.rename(columns={0: \"ratio_cnt\", 1: \"temp_diff\", 2: \"heat\", \n",
    "                         3: \"total_count\",\n",
    "                         4: \"season\", 5: \"year\", 6: \"month\", 7: \"hour\", 8: \"is_holiday\", 9: \"weekday\",\n",
    "                         10: \"is_workingday\", 11: \"weather_condition\", 12: \"windspeed\"\n",
    "                        }, inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing sets (randomly and stratified)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features.drop('total_count', axis=1),\n",
    "                                                    features['total_count'],\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=None,\n",
    "                                                    random_state=42)\n",
    "# Training data used for model developement\n",
    "x_train.reset_index(inplace=True)\n",
    "y_train = y_train.reset_index()\n",
    "\n",
    "# Set aside a hold-out test data used for final model performance\n",
    "x_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()\n",
    "\n",
    "y_train = y_train['total_count']\n",
    "y_test = y_test['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup estimator\n",
    "lgbmr = lgbm.sklearn.LGBMRegressor(boosting_type='gbdt', \n",
    "                               objective='regression',\n",
    "                               min_child_samples=10,  \n",
    "                               max_depth=-1,\n",
    "                               categorical_feature=cat_attr_list,\n",
    "                               nthread=-1,\n",
    "                               random_state=42\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt',\n",
       "       categorical_feature=['season', 'is_holiday', 'weather_condition', 'is_workingday', 'hour', 'weekday', 'month'],\n",
       "       class_weight=None, colsample_bytree=1.0, importance_type='split',\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=10,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "       n_jobs=-1, nthread=-1, num_leaves=31, objective='regression',\n",
       "       random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "lgbmr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbmr.predict(x_test)\n",
    "lgbm_mae = mean_absolute_error(y_pred, y_test)\n",
    "lgbm_train_mae = mean_absolute_error(lgbmr.predict(x_train), y_train)\n",
    "lgbm_variance = abs(lgbm_train_mae - lgbm_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"Mean Absolute Deviation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------------+\n",
      "|     Model     | Mean Absolute Deviation |\n",
      "+---------------+-------------------------+\n",
      "| LGBMRegressor |          46.81          |\n",
      "+---------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance using CV Mean absolute error regression loss\n",
    "mae_cv = -np.mean(cross_val_score(lgbmr, X_train, y_train, cv=3, n_jobs=-1, scoring=\"neg_mean_absolute_error\"))    \n",
    "\n",
    "table.add_row([type(lgbmr).__name__, \n",
    "               format(mae_cv, '.2f'), \n",
    "               ])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAD for LGBMRegressor model was 46.81 on the test dataset. This model train on a dataset based on engineered features did not performed any better compared to the non-featured engineer modeling. We can conclude that including these specific engineared features as opposed to the raw feature values does not benifit the models performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "With these three forms of modelling, there was still not much accuracy in predicting the use of bike sharing per day, using only the data about weather and time of the year (ie, day of week or month/season). When originally plotted the data to observe any clear correlations, we found that a lot of the data is roughly, but not strongly correlated to amount of uses. As a matter of fact, the most important factor was the hour of day, which only had a correlation of about 0.51 (quick calculation performed outside these notebooks). For most of the independent features, there was not a strong connection to the count target with the exception of humidity and temparature related features.\n",
    "\n",
    "However, while not exactly the most accurate predictions, we did discover a few key points along the way, there was a connection between the amount of uses and weather and type of day. For instance, when felt temperature was high and windspeed was low, more people used the bike sharing method, most likely because it is nicer out and they prefer using bikes over other public transportation methods. As well, we found that the original assumption, that more bikes were used on weekends, to be inaccurate, signaling that people might be using shared bikes during the week to get to and to cummute to and from work or school.\n",
    "\n",
    "Lastly, in the next notebook we tackle model optimization to train the selected model more robustly resulting in a model that would generalize better to new unseet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
