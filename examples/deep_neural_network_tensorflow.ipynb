{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_neural_network_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8NmRbYrVCx-",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning modeling on MNIST data set\n",
        "\n",
        "We will use MNIST data set to perform multi-class  (10 class labels) classification of digit data using Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133AXO2UU3Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7htrHQnVIwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset any previous graphs and start session\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRYrzt2CVQtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restart TensorBoard to see the result\n",
        "LOGDIR = './graphs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rkkq73-VV26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "19014444-f787-4a84-9bdf-72858203b41a"
      },
      "source": [
        "# Set input data (one-hot-encode features)\n",
        "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-556c649dc745>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln9U-a-oVaqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of neurons in each hidden layer\n",
        "HIDDEN1_SIZE = 500\n",
        "HIDDEN2_SIZE = 250\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_PIXELS = 28 * 28\n",
        "\n",
        "# Experiment with the nubmer of training steps to \n",
        "# see the effect\n",
        "TRAIN_STEPS = 2000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Set learning rate\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E081KTXtVu3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define inputs\n",
        "with tf.name_scope('input'):\n",
        "    images = tf.placeholder(tf.float32, [None, NUM_PIXELS],  name=\"pixels\")\n",
        "    labels = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWq6vpknVzqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create a Fully Connected (FC) layer\n",
        "def fc_layer(input, size_out, name=\"fc\", activation=None):\n",
        "  \n",
        "    with tf.name_scope(name):\n",
        "        size_in = int(input.shape[1])\n",
        "        \n",
        "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"weights\")\n",
        "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"bias\")\n",
        "        \n",
        "        wx_plus_b = tf.matmul(input, w) + b\n",
        "        \n",
        "        if activation: \n",
        "          return activation(wx_plus_b)\n",
        "        \n",
        "        return wx_plus_b\n",
        "      \n",
        "# The way we initialize variables has an affect on how quickly \n",
        "# training converges. We may explore with different strategies later.\n",
        "# w = tf.Variable(tf.truncated_normal(shape=[size_in, size_out], stddev=1.0 / math.sqrt(float(size_in))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ynderGpV_r0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e3e666e9-b110-4cc2-c39f-9678c57d99b6"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "# Create two fully connected layers, with ReLU activations\n",
        "fc1 = fc_layer(images, HIDDEN1_SIZE, \"fc1\", activation=tf.nn.relu)\n",
        "fc2 = fc_layer(fc1, HIDDEN2_SIZE, \"fc2\", activation=tf.nn.relu)\n",
        "\n",
        "# Next, apply Dropout to the second layer\n",
        "# This can help prevent overfitting\n",
        "keep_prob = 0.9\n",
        "dropped = tf.nn.dropout(fc2, rate=(1 - keep_prob)) \n",
        "\n",
        "# Finally, we'll calculate logists. This will be\n",
        "# the input to our Softmax function. \n",
        "y = fc_layer(dropped, NUM_CLASSES, name=\"output\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQsp5Lj4WNtz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2bb379f4-57c6-46bb-b619-6bf572734592"
      },
      "source": [
        "# Define loss and an optimizer\n",
        "with tf.name_scope(\"loss\"):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=labels))\n",
        "    tf.summary.scalar('loss', loss)\n",
        "\n",
        "with tf.name_scope(\"optimizer\"):\n",
        "    # TensorFlow will still automatically analyze our graph\n",
        "    # and determine how to adjust the variables to decrease the loss.\n",
        "    train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-ff2e5c97b413>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpXdjrn3WV3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define evaluation\n",
        "with tf.name_scope(\"evaluation\"):\n",
        "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # summarize sample evaluation\n",
        "    tf.summary.scalar('accuracy', accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XmgG0yuWXwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up logging.\n",
        "# We'll use a second FileWriter to summarize accuracy on\n",
        "# the test set. This will let us display it nicely in TensorBoard.\n",
        "train_writer = tf.summary.FileWriter(os.path.join(LOGDIR, \"train\"))\n",
        "train_writer.add_graph(sess.graph)\n",
        "\n",
        "test_writer  = tf.summary.FileWriter(os.path.join(LOGDIR, \"test\"))\n",
        "summary_op   = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrQRpd6wWZa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run TensorFlow graph session\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzs4lyHwWb4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9685a407-cfa9-4721-8137-e184a1456cd4"
      },
      "source": [
        "for step in range(TRAIN_STEPS):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
        "    # summarize session\n",
        "    summary_result, _ = sess.run([summary_op, train], \n",
        "                                    feed_dict={images: batch_xs, labels: batch_ys})\n",
        "\n",
        "    train_writer.add_summary(summary_result, step)\n",
        "    train_writer.add_run_metadata(tf.RunMetadata(), 'step%03d' % step)\n",
        "    \n",
        "    # calculate accuracy on the test set, every 100 steps.\n",
        "    # we're using the entire test set here, so this will be a bit slow\n",
        "    if step % 100 == 0:\n",
        "        summary_result, acc = sess.run([summary_op, accuracy], \n",
        "                                       feed_dict={images: mnist.test.images, \n",
        "                                                  labels: mnist.test.labels})\n",
        "        test_writer.add_summary(summary_result, step)\n",
        "        test_writer.add_run_metadata(tf.RunMetadata(), 'step%03d' % step)\n",
        "        print (\"test accuracy: %f at step %d\" % (acc, step))\n",
        "\n",
        "\n",
        "print(\"Accuracy %f\" % sess.run(accuracy, \n",
        "                               feed_dict={images: mnist.test.images,\n",
        "                                          labels: mnist.test.labels}))\n",
        "train_writer.close()\n",
        "test_writer.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.213500 at step 0\n",
            "test accuracy: 0.919800 at step 100\n",
            "test accuracy: 0.938300 at step 200\n",
            "test accuracy: 0.951400 at step 300\n",
            "test accuracy: 0.956100 at step 400\n",
            "test accuracy: 0.959900 at step 500\n",
            "test accuracy: 0.965800 at step 600\n",
            "test accuracy: 0.967100 at step 700\n",
            "test accuracy: 0.965700 at step 800\n",
            "test accuracy: 0.968600 at step 900\n",
            "test accuracy: 0.972200 at step 1000\n",
            "test accuracy: 0.971600 at step 1100\n",
            "test accuracy: 0.973900 at step 1200\n",
            "test accuracy: 0.971200 at step 1300\n",
            "test accuracy: 0.970200 at step 1400\n",
            "test accuracy: 0.975500 at step 1500\n",
            "test accuracy: 0.968400 at step 1600\n",
            "test accuracy: 0.975300 at step 1700\n",
            "test accuracy: 0.976400 at step 1800\n",
            "test accuracy: 0.974900 at step 1900\n",
            "Accuracy 0.974200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q9f29YCggVd",
        "colab_type": "text"
      },
      "source": [
        "Although this is a simple model, we can achieve about >97% accuracy on MNIST. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3xPQof4W1GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}